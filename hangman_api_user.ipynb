{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trexquant Interview Project (The Hangman Game)\n",
    "\n",
    "* Copyright Trexquant Investment LP. All Rights Reserved. \n",
    "* Redistribution of this question without written consent from Trexquant is prohibited"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction:\n",
    "For this coding test, your mission is to write an algorithm that plays the game of Hangman through our API server. \n",
    "\n",
    "When a user plays Hangman, the server first selects a secret word at random from a list. The server then returns a row of underscores (space separated)—one for each letter in the secret word—and asks the user to guess a letter. If the user guesses a letter that is in the word, the word is redisplayed with all instances of that letter shown in the correct positions, along with any letters correctly guessed on previous turns. If the letter does not appear in the word, the user is charged with an incorrect guess. The user keeps guessing letters until either (1) the user has correctly guessed all the letters in the word\n",
    "or (2) the user has made six incorrect guesses.\n",
    "\n",
    "You are required to write a \"guess\" function that takes current word (with underscores) as input and returns a guess letter. You will use the API codes below to play 1,000 Hangman games. You have the opportunity to practice before you want to start recording your game results.\n",
    "\n",
    "Your algorithm is permitted to use a training set of approximately 250,000 dictionary words. Your algorithm will be tested on an entirely disjoint set of 250,000 dictionary words. Please note that this means the words that you will ultimately be tested on do NOT appear in the dictionary that you are given. You are not permitted to use any dictionary other than the training dictionary we provided. This requirement will be strictly enforced by code review.\n",
    "\n",
    "You are provided with a basic, working algorithm. This algorithm will match the provided masked string (e.g. a _ _ l e) to all possible words in the dictionary, tabulate the frequency of letters appearing in these possible words, and then guess the letter with the highest frequency of appearence that has not already been guessed. If there are no remaining words that match then it will default back to the character frequency distribution of the entire dictionary.\n",
    "\n",
    "This benchmark strategy is successful approximately 18% of the time. Your task is to design an algorithm that significantly outperforms this benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import random\n",
    "import string\n",
    "import secrets\n",
    "import time\n",
    "import re\n",
    "import collections\n",
    "\n",
    "try:\n",
    "    from urllib.parse import parse_qs, urlencode, urlparse\n",
    "except ImportError:\n",
    "    from urlparse import parse_qs, urlparse\n",
    "    from urllib import urlencode\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis (EDA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the words dictionary in a dataframe and replacing '\\n' with blank space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dictinary = open(\"words_250000_train.txt\", \"r\")\n",
    "df = []\n",
    "for x in words_dictinary:\n",
    "  df.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df[i] = df[i].replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels_list = ['a', 'e', 'i', 'o', 'u']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for calculating ratio of vowels to length of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vowel_count(word):\n",
    "    count = 0\n",
    "    \n",
    "    for i in word:\n",
    "        if i in vowels_list:\n",
    "            count = count+1.0\n",
    "    return count/len(word)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying the vowel_count function over the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    227300.000000\n",
       "mean          0.386889\n",
       "std           0.095527\n",
       "min           0.000000\n",
       "25%           0.333333\n",
       "50%           0.384615\n",
       "75%           0.444444\n",
       "max           1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowel_count_for_given_length=[]\n",
    "for words in df:\n",
    "    vowel_count_for_given_length.append(vowel_count(words))\n",
    "vowel_count_for_given_length = pd.Series(vowel_count_for_given_length)\n",
    "vowel_count_for_given_length.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAKyCAYAAADIG729AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABMXElEQVR4nO3debiVdb3//9dm2IIDIipTThQmoCCJgltzKpLMSlI7qKQcRf1pYAnlUBoOlak5HweOmmKpOWQ5gKEcDEwkUZQjmqCm6enIRk0RRRGE+/dHh/V157S3cbvY8HhcF9flvtdn3eu9Vrcrn9xr3bumKIoiAAAAwErXotoDAAAAwOpKdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHTzHo8++mi1R4AP5RilOXCc0hw4TmkOHKc0d6Kb91i8eHG1R4AP5RilOXCc0hw4TmkOHKc0d6IbAAAASiK6AQAAoCSiGwAAAEoiugEAAKAkohsAAABKIroBAACgJKIbAAAASiK6AQAAoCSiGwAAAEoiugEAAKAkohsAAABKIroBAACgJKIbAAAASiK6AQAAoCSiGwAAAEoiugEAAKAkohsAAABKIroBAACgJKIbAAAASiK6AQAAoCSiGwAAAEoiugEAAKAkohsAAABKIroBAACgJKIbAAAASlL16P7f//3ffOtb38qGG26Ytm3bpnfv3nnooYcqtxdFkTFjxqRLly5p27ZtBg4cmKeeeqrBPl555ZUMHTo07dq1S/v27TN8+PC88cYbDdY8+uij2WWXXdKmTZtsuummOfvss98zy80335wePXqkTZs26d27d+68885ynjQAAABrhKpG96uvvpqdd945rVu3zu9///v8+c9/zrnnnpsNNtigsubss8/ORRddlLFjx+aBBx7IOuusk0GDBmXx4sWVNUOHDs3jjz+eSZMmZfz48bn33ntz5JFHVm5fuHBh9txzz2y++eaZOXNmfv7zn+fUU0/N5ZdfXllz//3358ADD8zw4cPzyCOPZPDgwRk8eHAee+yxT+bFAAAAYLVTUxRFUa0HP/HEEzNt2rT88Y9/fN/bi6JI165d873vfS/f//73kySvvfZaOnXqlHHjxuWAAw7IE088kV69euXBBx/M9ttvnySZOHFivvKVr+Rvf/tbunbtmssuuywnnXRS6uvrU1tbW3nsW2+9NXPmzEmSDBkyJIsWLcr48eMrj7/jjjumb9++GTt2bJkvwypnxowZ6d+/f7XHgA/kGKU5cJzSHDhOaQ4cpzR3rar54LfffnsGDRqUb37zm5k6dWo+9alP5dvf/naOOOKIJMmzzz6b+vr6DBw4sHKf9ddfPwMGDMj06dNzwAEHZPr06Wnfvn0luJNk4MCBadGiRR544IF84xvfyPTp07PrrrtWgjtJBg0alLPOOiuvvvpqNthgg0yfPj2jR49uMN+gQYNy6623lvsiALBaKhaenuX1T1Z7jEZp0bl5zAkAzVFVP17+zDPP5LLLLsuWW26Zu+66K0cffXS+853v5JprrkmS1NfXJ0k6derU4H6dOnWq3FZfX5+OHTs2uL1Vq1bp0KFDgzXvt493P8YHrVlxOwAAADRVVc90L1++PNtvv33OOOOMJMnnPve5PPbYYxk7dmyGDRtWzdFK8+ijjzb4Pvqq6Lnnnqv2CPChHKM0B8/N6/jRi1YRNc/PqPYIVIn3U5oDxymrssZ89aGq0d2lS5f06tWrwbaePXvmlltuSZJ07tw5STJ//vx06dKlsmb+/Pnp27dvZc2LL77YYB/vvPNOXnnllcr9O3funPnz5zdYs+Lnj1qz4vaVpU+fPit1f2XxvRlWdY5RVnXFwtOzwzbN42PbLTr792lN5v2U5sBxSnNW1Y+X77zzzpk7d26DbU8++WQ233zzJEm3bt3SuXPnTJ48uXL7woUL88ADD6Suri5JUldXlwULFmTmzJmVNffcc0+WL1+eAQMGVNbce++9Wbp0aWXNpEmTstVWW1WulF5XV9fgcVasWfE4AAAA0FRVje5Ro0blT3/6U84444w8/fTTuf7663P55ZdnxIgRSZKampoce+yx+clPfpLbb789s2fPziGHHJKuXbtm8ODBSf5xZvzLX/5yjjjiiMyYMSPTpk3LyJEjc8ABB6Rr165JkoMOOii1tbUZPnx4Hn/88dx444258MILG1w47bvf/W4mTpyYc889N3PmzMmpp56ahx56KCNHjvzEXxcAAABWD1X9ePkOO+yQ3/3ud/nBD36Q008/Pd26dcsFF1yQoUOHVtYcf/zxWbRoUY488sgsWLAgn//85zNx4sS0adOmsua6667LyJEj88UvfjEtWrTIfvvtl4suuqhy+/rrr5+77747I0aMSL9+/bLRRhtlzJgxDX6X90477ZTrr78+J598cn74wx9myy23zK233pptttnmk3kxAAAAWO1U9fd0s2ryuxBZ1TlGaQ4e+K+vNqPvdDePOVn5vJ/SHDhOae6q+vFyAAAAWJ2JbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoSVWj+9RTT01NTU2DPz169Kjcvnjx4owYMSIbbrhh1l133ey3336ZP39+g308//zz2XvvvbP22munY8eOOe644/LOO+80WDNlypRst912WWuttdK9e/eMGzfuPbNccskl2WKLLdKmTZsMGDAgM2bMKOU5AwAAsOao+pnurbfeOvPmzav8ue+++yq3jRo1KnfccUduvvnmTJ06NS+88EL23Xffyu3Lli3L3nvvnSVLluT+++/PNddck3HjxmXMmDGVNc8++2z23nvv7LHHHpk1a1aOPfbYHH744bnrrrsqa2688caMHj06p5xySh5++OFsu+22GTRoUF588cVP5kUAAABgtVT16G7VqlU6d+5c+bPRRhslSV577bX84he/yHnnnZcvfOEL6devX66++urcf//9+dOf/pQkufvuu/PnP/851157bfr27Zu99torP/7xj3PJJZdkyZIlSZKxY8emW7duOffcc9OzZ8+MHDky+++/f84///zKDOedd16OOOKIHHrooenVq1fGjh2btddeO1ddddUn/4IAAACw2qh6dD/11FPp2rVrPv3pT2fo0KF5/vnnkyQzZ87M0qVLM3DgwMraHj16ZLPNNsv06dOTJNOnT0/v3r3TqVOnyppBgwZl4cKFefzxxytr3r2PFWtW7GPJkiWZOXNmgzUtWrTIwIEDK2sAAADg42hVzQcfMGBAxo0bl6222irz5s3Laaedll122SWPPfZY6uvrU1tbm/bt2ze4T6dOnVJfX58kqa+vbxDcK25fcduHrVm4cGHeeuutvPrqq1m2bNn7rpkzZ87KfLpJkkcffTSLFy9e6ftdmZ577rlqjwAfyjFKc/DcvI7VHqHRap53HZM1lfdTmgPHKauy/v37f+Saqkb3XnvtVfnnPn36ZMCAAdl8881z0003pW3btlWcrDx9+vSp9giN0piDB6rJMcqqrlh4enbY5slqj9EoLTr792lN5v2U5sBxSnNW9Y+Xv1v79u3z2c9+Nk8//XQ6d+6cJUuWZMGCBQ3WzJ8/P507d06SdO7c+T1XM1/x80etadeuXdq2bZuNNtooLVu2fN81K/YBAAAAH8cqFd1vvPFG/vKXv6RLly7p169fWrduncmTJ1dunzt3bp5//vnU1dUlSerq6jJ79uwGVxmfNGlS2rVrl169elXWvHsfK9as2EdtbW369evXYM3y5cszefLkyhoAAAD4OKoa3d///vczderU/PWvf83999+fb3zjG2nZsmUOPPDArL/++hk+fHhGjx6dP/zhD5k5c2YOPfTQ1NXVZccdd0yS7LnnnunVq1cOPvjg/Pd//3fuuuuunHzyyRkxYkTWWmutJMlRRx2VZ555Jscff3zmzJmTSy+9NDfddFNGjRpVmWP06NG54oorcs011+SJJ57I0UcfnUWLFuXQQw+tyusCAADA6qGq3+n+29/+lgMPPDB///vfs/HGG+fzn/98/vSnP2XjjTdOkpx//vlp0aJF9ttvv7z99tsZNGhQLr300sr9W7ZsmfHjx+foo49OXV1d1llnnQwbNiynn356ZU23bt0yYcKEjBo1KhdeeGE22WSTXHnllRk0aFBlzZAhQ/LSSy9lzJgxqa+vT9++fTNx4sT3XFwNAAAAmqKmKIqi2kOwapkxY4aLVbBKc4zSHDzwX19tRhdSax5zsvJ5P6U5cJzS3K1S3+kGAACA1YnoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSiG4AAAAoiegGAACAkohuAAAAKInoBgAAgJKIbgAAACiJ6AYAAICSrDLRfeaZZ6ampibHHntsZdvixYszYsSIbLjhhll33XWz3377Zf78+Q3u9/zzz2fvvffO2muvnY4dO+a4447LO++802DNlClTst1222WttdZK9+7dM27cuPc8/iWXXJItttgibdq0yYABAzJjxowyniYAAABrkFUiuh988MH853/+Z/r06dNg+6hRo3LHHXfk5ptvztSpU/PCCy9k3333rdy+bNmy7L333lmyZEnuv//+XHPNNRk3blzGjBlTWfPss89m7733zh577JFZs2bl2GOPzeGHH5677rqrsubGG2/M6NGjc8opp+Thhx/Otttum0GDBuXFF18s/8kDAACw2qp6dL/xxhsZOnRorrjiimywwQaV7a+99lp+8Ytf5LzzzssXvvCF9OvXL1dffXXuv//+/OlPf0qS3H333fnzn/+ca6+9Nn379s1ee+2VH//4x7nkkkuyZMmSJMnYsWPTrVu3nHvuuenZs2dGjhyZ/fffP+eff37lsc4777wcccQROfTQQ9OrV6+MHTs2a6+9dq666qpP9sUAAABgtVL16B4xYkT23nvvDBw4sMH2mTNnZunSpQ229+jRI5tttlmmT5+eJJk+fXp69+6dTp06VdYMGjQoCxcuzOOPP15Z88/7HjRoUGUfS5YsycyZMxusadGiRQYOHFhZAwAAAB9Hq2o++A033JCHH344Dz744Htuq6+vT21tbdq3b99ge6dOnVJfX19Z8+7gXnH7its+bM3ChQvz1ltv5dVXX82yZcved82cOXP+pef3fh599NEsXrx4pe93ZXruueeqPQJ8KMcozcFz8zpWe4RGq3nedUzWVN5PaQ4cp6zK+vfv/5Frqhbd//M//5Pvfve7mTRpUtq0aVOtMT5x//y99VVVYw4eqCbHKKu6YuHp2WGbJ6s9RqO06OzfpzWZ91OaA8cpzVnVPl4+c+bMvPjii9luu+3SqlWrtGrVKlOnTs1FF12UVq1apVOnTlmyZEkWLFjQ4H7z589P586dkySdO3d+z9XMV/z8UWvatWuXtm3bZqONNkrLli3fd82KfQAAAMDHUbXo/uIXv5jZs2dn1qxZlT/bb799hg4dWvnn1q1bZ/LkyZX7zJ07N88//3zq6uqSJHV1dZk9e3aDq4xPmjQp7dq1S69evSpr3r2PFWtW7KO2tjb9+vVrsGb58uWZPHlyZQ0AAAB8HFX7ePl6662XbbbZpsG2ddZZJxtuuGFl+/DhwzN69Oh06NAh7dq1yzHHHJO6urrsuOOOSZI999wzvXr1ysEHH5yzzz479fX1OfnkkzNixIistdZaSZKjjjoqF198cY4//vgcdthhueeee3LTTTdlwoQJlccdPXp0hg0blu233z79+/fPBRdckEWLFuXQQw/9hF4NAAAAVkdVvZDaRzn//PPTokWL7Lfffnn77bczaNCgXHrppZXbW7ZsmfHjx+foo49OXV1d1llnnQwbNiynn356ZU23bt0yYcKEjBo1KhdeeGE22WSTXHnllRk0aFBlzZAhQ/LSSy9lzJgxqa+vT9++fTNx4sT3XFwNAAAAmqKmKIqi2kOwapkxY4aLVbBKc4zSHDzwX19tRhdSax5zsvJ5P6U5cJzS3FX993QDAADA6kp0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACUpFW1BwCAppj6189We4RGaZPmMScAUC5nugEAAKAkohsAAABKIroBAACgJKIbAAAASuJCagDknr9uVe0RGq1ltQcAAGgCZ7oBAACgJKIbAAAASiK6AQAAoCSN+k73o48+2ugd9unT52MPAwAAAKuTRkV33759U1NTk6IoUlNT86Frly1btlIGAwAAgOauUR8vf/bZZ/PMM8/k2WefzS233JJu3brl0ksvzSOPPJJHHnkkl156aT7zmc/klltuKXteAAAAaDYadaZ78803r/zzN7/5zVx00UX5yle+UtnWp0+fbLrppvnRj36UwYMHr/QhAQAAoDlq8oXUZs+enW7dur1ne7du3fLnP/95pQwFAAAAq4MmR3fPnj3zs5/9LEuWLKlsW7JkSX72s5+lZ8+eK3U4AAAAaM4a9fHydxs7dmy+9rWvZZNNNqlcqfzRRx9NTU1N7rjjjpU+IAAAADRXTY7u/v3755lnnsl1112XOXPmJEmGDBmSgw46KOuss85KHxAAAACaqyZF99KlS9OjR4+MHz8+Rx55ZFkzAQAAwGqhSd/pbt26dRYvXlzWLAAAALBaafKF1EaMGJGzzjor77zzThnzAAAAwGqjyd/pfvDBBzN58uTcfffd6d2793u+x/3b3/52pQ0HAAAAzVmTo7t9+/bZb7/9ypgFAAAAVitNju6rr766jDkAAABgtdPk6F7hpZdeyty5c5MkW221VTbeeOOVNhQAAACsDpp8IbVFixblsMMOS5cuXbLrrrtm1113TdeuXTN8+PC8+eabZcwIAAAAzVKTo3v06NGZOnVq7rjjjixYsCALFizIbbfdlqlTp+Z73/teGTMCAABAs9Tkj5ffcsst+c1vfpPdd9+9su0rX/lK2rZtm3/7t3/LZZddtjLnAwAAgGaryWe633zzzXTq1Ok92zt27Ojj5QAAAPAuTY7uurq6nHLKKVm8eHFl21tvvZXTTjstdXV1K3U4AAAAaM6a/PHyCy+8MIMGDcomm2ySbbfdNkny3//932nTpk3uuuuulT4gAAAANFdNju5tttkmTz31VK677rrMmTMnSXLggQdm6NChadu27UofEAAAAJqrj/V7utdee+0cccQRK3sWAAAAWK00Obo322yz7L777tltt92yxx575NOf/nQZcwEAAECz1+QLqZ1xxhlp06ZNzjrrrHTv3j2bbrppvvWtb+WKK67IU089VcaMAAAA0Cw1+Uz3t771rXzrW99KksybNy9Tp07N+PHj8+1vfzvLly/PsmXLVvqQAAAA0Bx9rO90v/nmm7nvvvsyZcqU/OEPf8gjjzySbbbZJrvvvvtKHg8AAACaryZH90477ZRHHnkkPXv2zO67754TTzwxu+66azbYYIMy5gMAAIBmq8nf6Z4zZ07WWWed9OjRIz169EjPnj0FNwAAALyPJp/p/vvf/57Zs2dnypQpueuuu3LSSSeltra2cjVzv0oM4P+545k+1R6hUdZp8l/BAgDQGE3+z6yampr06dMn3/nOd/Kb3/wmv//97/OlL30pN998c4466qgyZgQAAIBmqclnuh9++OFMmTIlU6ZMyX333ZfXX389vXv3zjHHHJPddtutjBkBAACgWWpydPfv3z+f+9znsttuu+WII47IrrvumvXXX7+M2QAAAKBZa3J0v/LKK2nXrl0ZswAAAMBqpcnf6RbcAAAA0DiuVwsAAAAlEd0AAABQkkZF98KFC8ueAwAAAFY7jYruDTbYIC+++GKS5Atf+EIWLFhQ5kwAAACwWmhUdK+77rr5+9//niSZMmVKli5dWupQAAAAsDpo1K8MGzhwYPbYY4/07NkzSfKNb3wjtbW177v2nnvuWXnTAQAAQDPWqOi+9tprc8011+Qvf/lLpk6dmq233jprr7122bMBAABAs9ao6G7btm2OOuqoJMlDDz2Us846K+3bty9zLgAAAGj2GhXd7/aHP/yh8s9FUSRJampqVt5EAAAAsJr4WL+n+5e//GV69+6dtm3bpm3btunTp09+9atfrezZAAAAoFlr8pnu8847Lz/60Y8ycuTI7LzzzkmS++67L0cddVRefvnljBo1aqUPCQAAAM1Rk6P7P/7jP3LZZZflkEMOqWz7+te/nq233jqnnnqq6AYAAID/0+SPl8+bNy877bTTe7bvtNNOmTdv3koZCgAAAFYHTY7u7t2756abbnrP9htvvDFbbrnlShkKAAAAVgdN/nj5aaedliFDhuTee++tfKd72rRpmTx58vvGOAAAAKypmnyme7/99ssDDzyQjTbaKLfeemtuvfXWbLTRRpkxY0a+8Y1vNGlfl112Wfr06ZN27dqlXbt2qaury+9///vK7YsXL86IESOy4YYbZt11181+++2X+fPnN9jH888/n7333jtrr712OnbsmOOOOy7vvPNOgzVTpkzJdtttl7XWWivdu3fPuHHj3jPLJZdcki222CJt2rTJgAEDMmPGjCY9FwAAAPhnTT7TnST9+vXLtdde+y8/+CabbJIzzzwzW265ZYqiyDXXXJN99tknjzzySLbeeuuMGjUqEyZMyM0335z1118/I0eOzL777ptp06YlSZYtW5a99947nTt3zv3335958+blkEMOSevWrXPGGWckSZ599tnsvffeOeqoo3Lddddl8uTJOfzww9OlS5cMGjQoyT8+Gj969OiMHTs2AwYMyAUXXJBBgwZl7ty56dix47/8PAEAAFgz1RRFUVR7iHfr0KFDfv7zn2f//ffPxhtvnOuvvz77779/kmTOnDnp2bNnpk+fnh133DG///3v89WvfjUvvPBCOnXqlCQZO3ZsTjjhhLz00kupra3NCSeckAkTJuSxxx6rPMYBBxyQBQsWZOLEiUmSAQMGZIcddsjFF1+cJFm+fHk23XTTHHPMMTnxxBM/4Veg+mbMmJH+/ftXewz4QM3pGL3jmT7VHqFR1mnxdrVHaLSWWaX+b+sDtXn6s9lhmyerPUajtOjcPOZk5WtO76esuRynNHdN/nh5WZYtW5YbbrghixYtSl1dXWbOnJmlS5dm4MCBlTU9evTIZpttlunTpydJpk+fnt69e1eCO0kGDRqUhQsX5vHHH6+sefc+VqxZsY8lS5Zk5syZDda0aNEiAwcOrKwBAACAj+Njfbx8ZZo9e3bq6uqyePHirLvuuvnd736XXr16ZdasWamtrU379u0brO/UqVPq6+uTJPX19Q2Ce8XtK277sDULFy7MW2+9lVdffTXLli173zVz5sxZmU81SfLoo49m8eLFK32/K9Nzzz1X7RHgQzWnY/Slv3+62iM0yms173z0olXEKvO3xR+h1UvN5+tJNc+7jsmaqjm9n7LmcpyyKmvMpzCqHt1bbbVVZs2alddeey2/+c1vMmzYsEydOrXaY5WmT5/m8VFTH+FhVddcjtH5zzxT7REaxcfLV742rdKMPl7ePP59ohzN5f2UNZvjlOas6tFdW1ub7t27J/nHBdoefPDBXHjhhRkyZEiWLFmSBQsWNDjbPX/+/HTu3DlJ0rlz5/dcZXzF1c3fveafr3g+f/78tGvXLm3btk3Lli3TsmXL912zYh8AAADwcay0T+ldeumlOf300//l/Sxfvjxvv/12+vXrl9atW2fy5MmV2+bOnZvnn38+dXV1SZK6urrMnj07L774YmXNpEmT0q5du/Tq1auy5t37WLFmxT5qa2vTr1+/BmuWL1+eyZMnV9YAAADAx7HSznTfcsstefbZZzNmzJhG3+cHP/hB9tprr2y22WZ5/fXXc/3112fKlCm56667sv7662f48OEZPXp0OnTokHbt2uWYY45JXV1ddtxxxyTJnnvumV69euXggw/O2Wefnfr6+px88skZMWJE1lprrSTJUUcdlYsvvjjHH398DjvssNxzzz256aabMmHChMoco0ePzrBhw7L99tunf//+ueCCC7Jo0aIceuihK+vlAQAAYA200qL7n88mN8aLL76YQw45JPPmzcv666+fPn365K677sqXvvSlJMn555+fFi1aZL/99svbb7+dQYMG5dJLL63cv2XLlhk/fnyOPvro1NXVZZ111smwYcManHHv1q1bJkyYkFGjRuXCCy/MJptskiuvvLLyO7qTZMiQIXnppZcyZsyY1NfXp2/fvpk4ceJ7Lq4GAAAATfEv/Z7uFXetqalZaQNRfX4XIqu65nSM+j3dK1+zuZCa39NNM9Cc3k9ZczlOae4+1ne6f/nLX6Z3795p27Zt2rZtmz59+uRXv/rVyp4NAAAAmrUmf7z8vPPOy49+9KOMHDkyO++8c5Lkvvvuy1FHHZWXX345o0aNWulDAgAAQHPU5Oj+j//4j1x22WU55JBDKtu+/vWvZ+utt86pp54qugEAAOD/NDm6582bl5122uk923faaafMmzdvpQwFAPDPrn96QLVHaLSDuj9Q7REAWEU0+Tvd3bt3z0033fSe7TfeeGO23HLLlTIUAAAArA6afKb7tNNOy5AhQ3LvvfdWvtM9bdq0TJ48+X1jHAAAANZUTT7Tvd9+++WBBx7IRhttlFtvvTW33nprNtpoo8yYMSPf+MY3ypgRAAAAmqUmn+lOkn79+uXaa69d2bMAAADAauVj/Z5uAAAA4KM1+kx3ixYtUlNT86Frampq8s477/zLQwEAAMDqoNHR/bvf/e4Db5s+fXouuuiiLF++fKUMBQAAAKuDRkf3Pvvs855tc+fOzYknnpg77rgjQ4cOzemnn75ShwMAAIDm7GN9p/uFF17IEUcckd69e+edd97JrFmzcs0112TzzTdf2fMBAABAs9Wk6H7ttddywgknpHv37nn88cczefLk3HHHHdlmm23Kmg8AAACarUZ/vPzss8/OWWedlc6dO+fXv/71+37cHAAAAPh/Gh3dJ554Ytq2bZvu3bvnmmuuyTXXXPO+637729+utOEAAACgOWt0dB9yyCEf+SvDAAAAgP+n0dE9bty4EscAAACA1c/Huno5AAAA8NFENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJqhrdP/vZz7LDDjtkvfXWS8eOHTN48ODMnTu3wZrFixdnxIgR2XDDDbPuuutmv/32y/z58xusef7557P33ntn7bXXTseOHXPcccflnXfeabBmypQp2W677bLWWmule/fuGTdu3HvmueSSS7LFFlukTZs2GTBgQGbMmLHSnzMAAABrjqpG99SpUzNixIj86U9/yqRJk7J06dLsueeeWbRoUWXNqFGjcscdd+Tmm2/O1KlT88ILL2Tfffet3L5s2bLsvffeWbJkSe6///5cc801GTduXMaMGVNZ8+yzz2bvvffOHnvskVmzZuXYY4/N4Ycfnrvuuquy5sYbb8zo0aNzyimn5OGHH862226bQYMG5cUXX/xkXgwAAABWOzVFURTVHmKFl156KR07dszUqVOz66675rXXXsvGG2+c66+/Pvvvv3+SZM6cOenZs2emT5+eHXfcMb///e/z1a9+NS+88EI6deqUJBk7dmxOOOGEvPTSS6mtrc0JJ5yQCRMm5LHHHqs81gEHHJAFCxZk4sSJSZIBAwZkhx12yMUXX5wkWb58eTbddNMcc8wxOfHEEz/hV6K6ZsyYkf79+1d7DPhAzekYveOZPtUeoVHWafF2tUdotJZZZf5v60O1efqz2WGbJ6s9RqO06Nw85rz+6QHVHqHRDur+QLVHaJTm9H7KmstxSnO3Sn2n+7XXXkuSdOjQIUkyc+bMLF26NAMHDqys6dGjRzbbbLNMnz49STJ9+vT07t27EtxJMmjQoCxcuDCPP/54Zc2797FizYp9LFmyJDNnzmywpkWLFhk4cGBlDQAAADTVKhPdy5cvz7HHHpudd94522yzTZKkvr4+tbW1ad++fYO1nTp1Sn19fWXNu4N7xe0rbvuwNQsXLsxbb72Vl19+OcuWLXvfNSv2AQAAAE3VqtoDrDBixIg89thjue+++6o9SqkeffTRLF68uNpjfKjnnnuu2iPAh2pOx+hLf/90tUdolNdq3vnoRauIVeZviz9Cq5c6VnuERqt5vnlcOHTBS5tXe4RGm/FK83hNm9P7KWsuxymrssZ89WGViO6RI0dm/Pjxuffee7PJJptUtnfu3DlLlizJggULGpztnj9/fjp37lxZ889XGV9xdfN3r/nnK57Pnz8/7dq1S9u2bdOyZcu0bNnyfdes2MfK0qdP8/h+p+/NsKprLsfo/GeeqfYIjeI73Stfm1ZpRt/pbh7/Pj39dPP5D+/+3ZvHa5o0n/dT1myOU5qzqp4wKIoiI0eOzO9+97vcc8896datW4Pb+/Xrl9atW2fy5MmVbXPnzs3zzz+furq6JEldXV1mz57d4CrjkyZNSrt27dKrV6/KmnfvY8WaFfuora1Nv379GqxZvnx5Jk+eXFkDAAAATVXVM90jRozI9ddfn9tuuy3rrbde5fvT66+/ftq2bZv1118/w4cPz+jRo9OhQ4e0a9cuxxxzTOrq6rLjjjsmSfbcc8/06tUrBx98cM4+++zU19fn5JNPzogRI7LWWmslSY466qhcfPHFOf7443PYYYflnnvuyU033ZQJEyZUZhk9enSGDRuW7bffPv37988FF1yQRYsW5dBDD/3kXxgAAABWC1WN7ssuuyxJsvvuuzfYfvXVV+ff//3fkyTnn39+WrRokf322y9vv/12Bg0alEsvvbSytmXLlhk/fnyOPvro1NXVZZ111smwYcNy+umnV9Z069YtEyZMyKhRo3LhhRdmk002yZVXXplBgwZV1gwZMiQvvfRSxowZk/r6+vTt2zcTJ058z8XVAAAAoLGqGt2N+RXhbdq0ySWXXJJLLrnkA9dsvvnmufPOOz90P7vvvnseeeSRD10zcuTIjBw58iNnAgAAgMZoLheBBQAAgGZHdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlKRVtQcAAKrrm/cfXe0RGuUbHas9AQA0nTPdAAAAUBLRDQAAACUR3QAAAFAS0Q0AAAAlEd0AAABQEtENAAAAJRHdAAAAUBLRDQAAACUR3QAAAFAS0Q0AAAAlEd0AAABQEtENAAAAJRHdAAAAUBLRDQAAACUR3QAAAFAS0Q0AAAAlEd0AAABQEtENAAAAJRHdAAAAUBLRDQAAACUR3QAAAFAS0Q0AAAAlqWp033vvvfna176Wrl27pqamJrfeemuD24uiyJgxY9KlS5e0bds2AwcOzFNPPdVgzSuvvJKhQ4emXbt2ad++fYYPH5433nijwZpHH300u+yyS9q0aZNNN900Z5999ntmufnmm9OjR4+0adMmvXv3zp133rnSny8AAABrlqpG96JFi7Ltttvmkksued/bzz777Fx00UUZO3ZsHnjggayzzjoZNGhQFi9eXFkzdOjQPP7445k0aVLGjx+fe++9N0ceeWTl9oULF2bPPffM5ptvnpkzZ+bnP/95Tj311Fx++eWVNffff38OPPDADB8+PI888kgGDx6cwYMH57HHHivvyQMAALDaa1XNB99rr72y1157ve9tRVHkggsuyMknn5x99tknSfLLX/4ynTp1yq233poDDjggTzzxRCZOnJgHH3ww22+/fZLkP/7jP/KVr3wl55xzTrp27ZrrrrsuS5YsyVVXXZXa2tpsvfXWmTVrVs4777xKnF944YX58pe/nOOOOy5J8uMf/ziTJk3KxRdfnLFjx34CrwQAAACro1X2O93PPvts6uvrM3DgwMq29ddfPwMGDMj06dOTJNOnT0/79u0rwZ0kAwcOTIsWLfLAAw9U1uy6666pra2trBk0aFDmzp2bV199tbLm3Y+zYs2KxwEAAICPY5WN7vr6+iRJp06dGmzv1KlT5bb6+vp07Nixwe2tWrVKhw4dGqx5v328+zE+aM2K2wEAAODjqOrHy9dEjz76aIPvpK+KnnvuuWqPAB+qOR2jL/3909UeoVFeq3mn2iM02ir7t8X/pNVLHT960Sqiw9/XrvYIjbLg1c2rPUKjzXhlRrVHaJTm9H7Kmstxyqqsf//+H7lmlY3uzp07J0nmz5+fLl26VLbPnz8/ffv2rax58cUXG9zvnXfeySuvvFK5f+fOnTN//vwGa1b8/FFrVty+MvXp02el77MMjTl4oJqayzE6/5lnqj1Co6zT4u1qj9BoLVNUe4RGadMq2WGbJ6s9RqOc88ym1R6hUdp3bD7/4d2/e/N4j0qaz/spazbHKc3ZKnvCoFu3buncuXMmT55c2bZw4cI88MADqaurS5LU1dVlwYIFmTlzZmXNPffck+XLl2fAgAGVNffee2+WLl1aWTNp0qRstdVW2WCDDSpr3v04K9aseBwAAAD4OKoa3W+88UZmzZqVWbNmJfnHxdNmzZqV559/PjU1NTn22GPzk5/8JLfffntmz56dQw45JF27ds3gwYOTJD179syXv/zlHHHEEZkxY0amTZuWkSNH5oADDkjXrl2TJAcddFBqa2szfPjwPP7447nxxhtz4YUXZvTo0ZU5vvvd72bixIk599xzM2fOnJx66ql56KGHMnLkyE/6JQEAAGA1UtWPlz/00EPZY489Kj+vCOFhw4Zl3LhxOf7447No0aIceeSRWbBgQT7/+c9n4sSJadOmTeU+1113XUaOHJkvfvGLadGiRfbbb79cdNFFldvXX3/93H333RkxYkT69euXjTbaKGPGjGnwu7x32mmnXH/99Tn55JPzwx/+MFtuuWVuvfXWbLPNNp/AqwAAAMDqqqrRvfvuu6coPvi7eTU1NTn99NNz+umnf+CaDh065Prrr//Qx+nTp0/++Mc/fuiab37zm/nmN7/54QMDAABAE6yy3+kGAACA5k50AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJSkVbUHAABY3fSf+MNqj9AoF3cYXO0RAFZ7znQDAABASUQ3AAAAlER0AwAAQElENwAAAJREdAMAAEBJRDcAAACURHQDAABASUQ3AAAAlER0AwAAQElENwAAAJSkVbUHAGiqnz02Ps+8eEe1x2iUn/Sq9gQAAFSTM90AAABQEtENAAAAJRHdAAAAUBLRDQAAACUR3QAAAFAS0Q0AAAAlEd0AAABQEtENAAAAJRHdAAAAUBLRDQAAACUR3QAAAFAS0Q0AAAAlEd0AAABQEtENAAAAJRHdAAAAUBLRDQAAACUR3QAAAFAS0Q0AAAAlEd0AAABQEtENAAAAJRHdAAAAUBLRDQAAACUR3QAAAFAS0Q0AAAAlEd0AAABQEtENAAAAJRHdAAAAUBLRDQAAACUR3QAAAFAS0Q0AAAAlEd0AAABQEtENAAAAJRHdAAAAUBLRDQAAACUR3QAAAFAS0Q0AAAAlEd0AAABQEtENAAAAJRHdAAAAUBLRDQAAACUR3QAAAFAS0Q0AAAAlEd0AAABQEtENAAAAJRHdAAAAUBLRDQAAACUR3QAAAFAS0Q0AAAAlaVXtAYBVx6cvOK/aIzTKtu2qPQEAADSOM90AAABQEtENAAAAJRHdAAAAUBLRDQAAACVxITXe47S7/5AnJ0+r9hgf6akfjKr2CAAAAB/KmW4AAAAoiTPdAACs8j770/OrPUKjPHmST+IBDTnTDQAAACUR3QAAAFASHy8HAFhD/XjCH/L0+FX/4qlJkrWqPQDAxyO6oWS9Tmoe30FLkmxc7QEAAGD14uPlAAAAUBLR/U8uueSSbLHFFmnTpk0GDBiQGTNmVHskAAAAminR/S433nhjRo8enVNOOSUPP/xwtt122wwaNCgvvvhitUcDAACgGRLd73LeeefliCOOyKGHHppevXpl7NixWXvttXPVVVdVezQAAACaIRdS+z9LlizJzJkz84Mf/KCyrUWLFhk4cGCmT59exckAAGDl2/7w86o9QqNceuTnqz0C/EtE9/95+eWXs2zZsnTq1KnB9k6dOmXOnDlVmgoAgOZkx281j5BNkrSp9gCNc/4Vk/O3n91b7TEa5Y+/+361R2AVJLp5jwknn1DtEVYrf/7pqGqPQFX9uNoDUC1bVHuAxru5c7UnWP0c1L3aEzTSl6s9AMDqz3e6/89GG22Uli1bZv78+Q22z58/P507+68RAAAAmk50/5/a2tr069cvkydPrmxbvnx5Jk+enLq6uipOBgAAQHPl4+XvMnr06AwbNizbb799+vfvnwsuuCCLFi3KoYceWu3RAAAAaIZE97sMGTIkL730UsaMGZP6+vr07ds3EydOfM/F1QAAAKAxaoqiKKo9BAAAAKyOfKcbAAAASiK6AQAAoCSiGwAAAEoiugEAAKAkohsAAABKIroBAACgJKJ7DXPJJZdkiy22SJs2bTJgwIDMmDHjQ9fffPPN6dGjR9q0aZPevXvnzjvv/IQmZU3WlOP0iiuuyC677JINNtggG2ywQQYOHPiRxzWsDE19P13hhhtuSE1NTQYPHlzugJCmH6cLFizIiBEj0qVLl6y11lr57Gc/6//7KV1Tj9MLLrggW221Vdq2bZtNN900o0aNyuLFiz+haaHpRPca5MYbb8zo0aNzyimn5OGHH862226bQYMG5cUXX3zf9ffff38OPPDADB8+PI888kgGDx6cwYMH57HHHvuEJ2dN0tTjdMqUKTnwwAPzhz/8IdOnT8+mm26aPffcM//7v//7CU/OmqSpx+kKf/3rX/P9738/u+yyyyc0KWuyph6nS5YsyZe+9KX89a9/zW9+85vMnTs3V1xxRT71qU99wpOzJmnqcXr99dfnxBNPzCmnnJInnngiv/jFL3LjjTfmhz/84Sc8OTReTVEURbWH4JMxYMCA7LDDDrn44ouTJMuXL8+mm26aY445JieeeOJ71g8ZMiSLFi3K+PHjK9t23HHH9O3bN2PHjv3E5mbN0tTj9J8tW7YsG2ywQS6++OIccsghZY/LGurjHKfLli3LrrvumsMOOyx//OMfs2DBgtx6662f4NSsaZp6nI4dOzY///nPM2fOnLRu3fqTHpc1VFOP05EjR+aJJ57I5MmTK9u+973v5YEHHsh99933ic0NTeFM9xpiyZIlmTlzZgYOHFjZ1qJFiwwcODDTp09/3/tMnz69wfokGTRo0Aeuh3/VxzlO/9mbb76ZpUuXpkOHDmWNyRru4x6np59+ejp27Jjhw4d/EmOyhvs4x+ntt9+eurq6jBgxIp06dco222yTM844I8uWLfukxmYN83GO05122ikzZ86sfAT9mWeeyZ133pmvfOUrn8jM8HG0qvYAfDJefvnlLFu2LJ06dWqwvVOnTpkzZ8773qe+vv5919fX15c2J2u2j3Oc/rMTTjghXbt2fc9fGMHK8nGO0/vuuy+/+MUvMmvWrE9gQvh4x+kzzzyTe+65J0OHDs2dd96Zp59+Ot/+9rezdOnSnHLKKZ/E2KxhPs5xetBBB+Xll1/O5z//+RRFkXfeeSdHHXWUj5ezSnOmG1htnHnmmbnhhhvyu9/9Lm3atKn2OJAkef3113PwwQfniiuuyEYbbVTtceADLV++PB07dszll1+efv36ZciQITnppJN8pYxVypQpU3LGGWfk0ksvzcMPP5zf/va3mTBhQn784x9XezT4QM50ryE22mijtGzZMvPnz2+wff78+encufP73qdz585NWg//qo9znK5wzjnn5Mwzz8x//dd/pU+fPmWOyRquqcfpX/7yl/z1r3/N1772tcq25cuXJ0latWqVuXPn5jOf+Uy5Q7PG+Tjvp126dEnr1q3TsmXLyraePXumvr4+S5YsSW1tbakzs+b5OMfpj370oxx88ME5/PDDkyS9e/fOokWLcuSRR+akk05KixbOKbLqcVSuIWpra9OvX78GF51Yvnx5Jk+enLq6uve9T11dXYP1STJp0qQPXA//qo9znCbJ2WefnR//+MeZOHFitt9++09iVNZgTT1Oe/TokdmzZ2fWrFmVP1//+tezxx57ZNasWdl0000/yfFZQ3yc99Odd945Tz/9dOUvhZLkySefTJcuXQQ3pfg4x+mbb775nrBe8RdFrg/NKqtgjXHDDTcUa621VjFu3Ljiz3/+c3HkkUcW7du3L+rr64uiKIqDDz64OPHEEyvrp02bVrRq1ao455xziieeeKI45ZRTitatWxezZ8+u1lNgDdDU4/TMM88samtri9/85jfFvHnzKn9ef/31aj0F1gBNPU7/2bBhw4p99tnnE5qWNVVTj9Pnn3++WG+99YqRI0cWc+fOLcaPH1907Nix+MlPflKtp8AaoKnH6SmnnFKst956xa9//evimWeeKe6+++7iM5/5TPFv//Zv1XoK8JF8vHwNMmTIkLz00ksZM2ZM6uvr07dv30ycOLFy8Yrnn3++wd8c7rTTTrn++utz8skn54c//GG23HLL3Hrrrdlmm22q9RRYAzT1OL3sssuyZMmS7L///g32c8opp+TUU0/9JEdnDdLU4xSqoanH6aabbpq77roro0aNSp8+ffKpT30q3/3ud3PCCSdU6ymwBmjqcXryySenpqYmJ598cv73f/83G2+8cb72ta/lpz/9abWeAnwkv6cbAAAASuKv4QEAAKAkohsAAABKIroBAACgJKIbAAAASiK6AQAAoCSiGwAAAEoiugEAAKAkohsAAABKIroBoMr++te/pqamJrNmzar2KKu1xrzO48aNS/v27T+xmT7KFltskQsuuKDaYwDwLxDdAMBK8e///u8ZPHjw+9721ltvZZ111snTTz/9yQ7VTKxqsQ/AyiO6AYDSTZo0KZtvvnm6d+9e+mMtWbKk9McAgMYS3QCscS6//PJ07do1y5cvb7B9n332yWGHHZYkueyyy/KZz3wmtbW12WqrrfKrX/2qsu773/9+vvrVr1Z+vuCCC1JTU5OJEydWtnXv3j1XXnll5ecrr7wyPXv2TJs2bdKjR49ceumlHzjfq6++mqFDh2bjjTdO27Zts+WWW+bqq6/+0Of0+OOP56tf/WratWuX9dZbL7vsskv+8pe/JEmWL1+e008/PZtssknWWmut9O3bt8GsU6ZMSU1NTRYsWFDZNmvWrNTU1OSvf/1rkv93Jvauu+5Kz549s+666+bLX/5y5s2blyQ59dRTc8011+S2225LTU1NampqMmXKlMr+brvttnz961/Pa6+9lpYtW+ahhx6qzNahQ4fsuOOOlbXXXnttNt1008rPs2fPzhe+8IW0bds2G264YY488si88cYbldtXnGH/6U9/mq5du2arrbZKksyYMSOf+9zn0qZNm2y//fZ55JFHPvQ1/CC33XZbtttuu7Rp0yaf/vSnc9ppp+Wdd96p3F5TU5Mrr7wy3/jGN7L22mtnyy23zO23395gH7fffnu23HLLtGnTJnvssUeuueaayms+ZcqUHHrooXnttdcqr92pp55aue+bb76Zww47LOutt14222yzXH755R/reQBQJQUArGFeeeWVora2tviv//qvyra///3vlW2//e1vi9atWxeXXHJJMXfu3OLcc88tWrZsWdxzzz1FURTF7bffXqy//vrFO++8UxRFUQwePLjYaKONihNOOKEoiqL429/+ViQpnnrqqaIoiuLaa68tunTpUtxyyy3FM888U9xyyy1Fhw4dinHjxhVFURTPPvtskaR45JFHiqIoihEjRhR9+/YtHnzwweLZZ58tJk2aVNx+++0f+Hz+9re/FR06dCj23Xff4sEHHyzmzp1bXHXVVcWcOXOKoiiK8847r2jXrl3x61//upgzZ05x/PHHF61bty6efPLJoiiK4g9/+EORpHj11Vcr+3zkkUeKJMWzzz5bFEVRXH311UXr1q2LgQMHFg8++GAxc+bMomfPnsVBBx1UFEVRvP7668W//du/FV/+8peLefPmFfPmzSvefvvtoiiKYtmyZUXHjh2L+++/vyiKothuu+2Kn//850VRFMWsWbOKDh06FLW1tcXrr79eFEVRHH744cXQoUOLoiiKN954o+jSpUux7777FrNnzy4mT55cdOvWrRg2bFhl1mHDhhXrrrtucfDBBxePPfZY8dhjjxWvv/56sfHGGxcHHXRQ8dhjjxV33HFH8elPf7rB6/x+rr766mL99dev/HzvvfcW7dq1K8aNG1f85S9/Ke6+++5iiy22KE499dTKmiTFJptsUlx//fXFU089VXznO98p1l133eLvf/97URRF8cwzzxStW7cuvv/97xdz5swpfv3rXxef+tSnKq/522+/XVxwwQVFu3btKq/ditdi8803Lzp06FBccsklxVNPPVX87Gc/K1q0aFH53xaAVZ/oBmCNtM8++xSHHXZY5ef//M//LLp27VosW7as2GmnnYojjjiiwfpvfvObxVe+8pWiKIri1VdfLVq0aFE8+OCDxfLly4sOHToUP/vZz4oBAwYURfGPyP7Upz5Vue9nPvOZ4vrrr2+wvx//+MdFXV1dURTvje6vfe1rxaGHHtro5/KDH/yg6NatW7FkyZL3vb1r167FT3/60wbbdthhh+Lb3/52URSNj+4kxdNPP11Zc8kllxSdOnWq/Dxs2LBin332ec/jT5s2rejYsWOxbNmyoiiKYvTo0cXee+9dFEVRXHDBBcWQIUOKbbfdtvj9739fFEVRdO/evbj88suLoiiKyy+/vNhggw2KN954o7K/CRMmFC1atCjq6+srj9upU6dK5BfFP/733HDDDYu33nqrsu2yyy5rcnR/8YtfLM4444wGa371q18VXbp0qfycpDj55JMrP7/xxhtFksrzOeGEE4ptttmmwT5OOumkBq/5Pz/uCptvvnnxrW99q/Lz8uXLi44dOxaXXXbZBz4HAFYtPl4OwBpp6NChueWWW/L2228nSa677roccMABadGiRZ544onsvPPODdbvvPPOeeKJJ5Ik7du3z7bbbpspU6Zk9uzZqa2tzZFHHplHHnkkb7zxRqZOnZrddtstSbJo0aL85S9/yfDhw7PuuutW/vzkJz+pfPz7nx199NG54YYb0rdv3xx//PG5//77K7fttddelX1svfXWSf7xUfBddtklrVu3fs++Fi5cmBdeeOFDn09jrb322vnMZz5T+blLly558cUXP/J+t912W7761a+mRYt//GfHbrvtlvvuuy/Lli3L1KlTs/vuu2f33XfPlClT8sILL+Tpp5/O7rvvniR54oknsu2222adddZpMPvy5cszd+7cyrbevXuntra28vMTTzyRPn36pE2bNpVtdXV1DebaeuutK6/lXnvt9b6z//d//3dOP/30Bv/bHXHEEZk3b17efPPNyro+ffpU/nmdddZJu3btKq/N3Llzs8MOOzTYb//+/T/ydXu/fdfU1KRz586Net0BWDW0qvYAAFANX/va11IURSZMmJAddtghf/zjH3P++ec3+v4rInGttdbKbrvtlg4dOqRnz5657777MnXq1Hzve99Lksp3j6+44ooMGDCgwT5atmz5vvvea6+98txzz+XOO+/MpEmT8sUvfjEjRozIOeeckyuvvDJvvfVWklQiu23btk1+/u+2IoaLoqhsW7p06XvW/XPU19TUNLjPB7n99ttz5plnVn7edddd8/rrr+fhhx/OvffemzPOOCOdO3fOmWeemW233TZdu3bNlltu2aTn8O4ob6w777yz8jw/6DV84403ctppp2Xfffd9z23vDvr3e23++ZoBH1eZ+wagfKIbgDVSmzZtsu++++a6667L008/na222irbbbddkqRnz56ZNm1ahg0bVlk/bdq09OrVq/LzbrvtlquuuiqtWrXKl7/85ST/CPFf//rXefLJJytnajt16pSuXbvmmWeeydChQxs938Ybb5xhw4Zl2LBh2WWXXXLcccflnHPOyac+9an3rO3Tp0+uueaaLF269D2B1q5du3Tt2jXTpk2rnH1f8XxWnG3deOONkyTz5s3LBhtskCQf63eG19bWZtmyZQ22PfXUU3nuuefypS99qbKtffv26dOnTy6++OK0bt06PXr0SMeOHTNkyJCMHz++wZw9e/bMuHHjsmjRokpYT5s2LS1atKhcMO399OzZM7/61a+yePHiShz/6U9/arBm8803/8jntN1222Xu3Ln/0lXXt9pqq9x5550Ntj344IMNfn6/1w6A1YOPlwOwxho6dGgmTJiQq666qkEQH3fccRk3blwuu+yyPPXUUznvvPPy29/+Nt///vcra1acrR0/fnwlsHffffdcd9116dKlSz772c9W1p522mn52c9+losuuihPPvlkZs+enauvvjrnnXfe+841ZsyY3HbbbXn66afz+OOPZ/z48enZs+cHPo+RI0dm4cKFOeCAA/LQQw/lqaeeyq9+9avKx6+PO+64nHXWWbnxxhszd+7cnHjiiZk1a1a++93vJvnHldY33XTTnHrqqXnqqacyYcKEnHvuuU1+PbfYYos8+uijmTt3bl5++eUsXbo0t912WwYOHJi11167wdoVr9WKwF7xSYEbb7yxQXQPHTo0bdq0ybBhw/LYY4/lD3/4Q4455pgcfPDB6dSp0wfOctBBB6WmpiZHHHFE/vznP+fOO+/MOeec0+TnNGbMmPzyl7/MaaedlscffzxPPPFEbrjhhpx88smN3sf/9//9f5kzZ05OOOGEPPnkk7npppsybty4JP84a53847V74403Mnny5Lz88ssNProOQPMmugFYY33hC19Ihw4dMnfu3Bx00EGV7YMHD86FF16Yc845J1tvvXX+8z//M1dffXUlrpNkgw02SO/evbPxxhunR48eSf4R4suXL28QjUly+OGH58orr8zVV1+d3r17Z7fddsu4cePSrVu3952rtrY2P/jBD9KnT5/suuuuadmyZW644YYPfB4bbrhh7rnnnrzxxhvZbbfd0q9fv1xxxRWVs97f+c53Mnr06Hzve99L7969M3HixMqvsEr+8fHlX//615kzZ0769OmTs846Kz/5yU+a/HoeccQR2WqrrbL99ttn4403zrRp0yq/Kuyf7bbbblm2bFmD13T33Xd/z7a11147d911V1555ZXssMMO2X///fPFL34xF1988YfOsu666+aOO+7I7Nmz87nPfS4nnXRSzjrrrCY/p0GDBmX8+PG5++67s8MOO2THHXfM+eef36iz5Ct069Ytv/nNb/Lb3/42ffr0yWWXXZaTTjopSbLWWmslSXbaaaccddRRGTJkSDbeeOOcffbZTZ4VgFVTTdGYL2MBADTRyy+/nC5duuRvf/vbh56VXhP99Kc/zdixY/M///M/1R4FgJL5TjcAUIpXXnkl5513nuBOcumll2aHHXbIhhtumGnTpuXnP/95Ro4cWe2xAPgEONMNAFCyUaNG5cYbb8wrr7ySzTbbLAcffHB+8IMfpFUr5z8AVneiGwAAAEriQmoAAABQEtENAAAAJRHdAAAAUBLRDQAAACUR3QAAAFAS0Q0AAAAlEd0AAABQEtENAAAAJRHdAAAAUJL/H0qzZRoZgL79AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the bins for the histogram\n",
    "bins = np.arange(0.0, 1.0, 0.05)\n",
    "\n",
    "# Creating histogram\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 7), tight_layout=True)\n",
    "\n",
    "# Remove axes splines\n",
    "for s in ['top', 'bottom', 'left', 'right']:\n",
    "    axs.spines[s].set_visible(False)\n",
    "\n",
    "# Remove x, y ticks\n",
    "axs.xaxis.set_ticks_position('none')\n",
    "axs.yaxis.set_ticks_position('none')\n",
    "\n",
    "# Add padding between axes and labels\n",
    "axs.xaxis.set_tick_params(pad=5)\n",
    "axs.yaxis.set_tick_params(pad=10)\n",
    "\n",
    "# Creating histogram\n",
    "N, bins, patches = axs.hist(x=vowel_count_for_given_length, bins=bins)\n",
    "\n",
    "# Setting color\n",
    "fracs = ((N**(1 / 5)) / N.max())\n",
    "norm = colors.Normalize(fracs.min(), fracs.max())\n",
    "\n",
    "for thisfrac, thispatch in zip(fracs, patches):\n",
    "    color = plt.cm.viridis(norm(thisfrac))\n",
    "    thispatch.set_facecolor(color)\n",
    "\n",
    "# Add x, y gridlines\n",
    "axs.grid( color='grey', linestyle='-', linewidth=0.5, alpha=0.6)\n",
    "\n",
    "# Adding extra features\n",
    "plt.xlabel(\"vowels-count/word-length\")\n",
    "plt.ylabel(\"No. of word\")\n",
    "# plt.title('Histogram')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot we can statiscally say that if the number of vowels in it are greater than 0.6 times of its length than guessing a vowel will not be a good choice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NGrams function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNGrams(guessed_word,n):\n",
    "    ngrams = {}\n",
    "    for word in guessed_word:\n",
    "        if len(word) <n:\n",
    "            continue\n",
    "        for i in range(len(word)-n+1):\n",
    "            ngram = word[i:i+n]\n",
    "            if ngram not in ngrams:\n",
    "                ngrams[ngram] = 1\n",
    "            else:\n",
    "                ngrams[ngram]+=1\n",
    "    return ngrams"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Testing NGrams function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d': 1, 'e': 1, '_': 1, 'f': 1}\n"
     ]
    }
   ],
   "source": [
    "word=[\"de_f\"]\n",
    "print(getNGrams(word,1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------MODEL DETAILS-------------------------------------------------\n",
      "\n",
      "RNN_model(\n",
      "  (lstm1): StatefulLSTM(\n",
      "    (lstm): LSTMCell(27, 16)\n",
      "  )\n",
      "  (bn_lstm1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout1): LockedDropout()\n",
      "  (fc): Linear(in_features=42, out_features=26, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.distributed as dist\n",
    "import collections\n",
    "# Check if CUDA is available\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "# Function to load the trained model from a given path\n",
    "def load_model(model_path):\n",
    "    model = RNN_model(target_dim=26, hidden_units=16)\n",
    "    checkpoint = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Function to display the game status - original word, guesses, and obscured words seen\n",
    "def show_game(original_word, guesses, obscured_words_seen):\n",
    "    print('Hidden word was \"{}\"'.format(original_word))\n",
    "\n",
    "    for i in range(len(guesses)):\n",
    "        word_seen = ''.join([chr(i + 97) if i != 26 else ' ' for i in obscured_words_seen[i].argmax(axis=1)])\n",
    "        print('Guessed {} after seeing \"{}\"'.format(guesses[i], word_seen))\n",
    "        \n",
    "# Function to convert a Python list to a PyTorch tensor\n",
    "def list_to_tensor_convertor(arr):\n",
    "    arr = np.array(arr)\n",
    "    return torch.from_numpy(arr)\n",
    "\n",
    "# Class to handle game logic and encoding for training\n",
    "class Word2Batch:\n",
    "    def __init__(self, model, word, lives=6):\n",
    "        self.origin_word = word\n",
    "        self.guessed_letter = set()   #Store guessed letters as indices\n",
    "        self.word_idx = [ord(i)-97 for i in word] # Convert characters to corresponding indices (0-25)\n",
    "        self.remain_letters = set(self.word_idx)  # Set of remaining letters to guess\n",
    "        self.model = model\n",
    "        self.lives_left = lives\n",
    "        self.guessed_letter_each = []\n",
    "\n",
    "        # Lists to store the dataset for variable-to-output (input-to-label) pairs\n",
    "        self.obscured_word_seen = []  # n * 27, where n is the number of guesses\n",
    "        self.prev_guessed = []  # n*26, where n is the number of guesses and each element is the normalized word idx\n",
    "        self.correct_response = []  # this is the label, meaning self.prev_guess should be one of self.correct_response\n",
    " \n",
    " # Function to convert guessed word into a one-hot encoded tensor\n",
    "    def converting_guessed_word(self):\n",
    "        word = [i if i in self.guessed_letter else 26 for i in self.word_idx]\n",
    "        obscured_word = np.zeros((len(word), 27), dtype=np.float32)\n",
    "        for i, j in enumerate(word):\n",
    "            obscured_word[i, j] = 1\n",
    "        return obscured_word\n",
    "\n",
    "# Function to encode the previous guesses into a one-hot encoded tensor\n",
    "    def encode_prev_guess(self):\n",
    "        guess = np.zeros(26, dtype=np.float32)\n",
    "        for i in self.guessed_letter:\n",
    "            guess[i] = 1.0\n",
    "        return guess\n",
    "\n",
    "    # Function to encode the correct response (remaining letters) into a one-hot encoded tensor\n",
    "    def encode_correct_response(self):\n",
    "        response = np.zeros(26, dtype=np.float32)\n",
    "        for i in self.remain_letters:\n",
    "            response[i] = 1.0\n",
    "        response /= response.sum()\n",
    "        return response\n",
    "    \n",
    "    # Function to play the game and mimic the gameplay for training data generation\n",
    "    def game_mimic(self):\n",
    "        obscured_words_seen = []\n",
    "        prev_guess_seen = []\n",
    "        correct_response_seen = []\n",
    "\n",
    "        while self.lives_left > 0 and len(self.remain_letters) > 0:\n",
    "            # Store obscured word and previous guesses as input (X) for the model\n",
    "            obscured_word = self.converting_guessed_word()\n",
    "            prev_guess = self.encode_prev_guess()\n",
    "\n",
    "            obscured_words_seen.append(obscured_word)\n",
    "            prev_guess_seen.append(prev_guess)\n",
    "            obscured_word = torch.from_numpy(obscured_word)\n",
    "            prev_guess = torch.from_numpy(prev_guess)\n",
    "            if CUDA:\n",
    "                obscured_word = obscured_word.cuda()\n",
    "                prev_guess = prev_guess.cuda()\n",
    "\n",
    "            self.model.eval()\n",
    "            guess = self.model(obscured_word, prev_guess)  # Output of guess should be a 1 by 26 vector\n",
    "            guess = torch.argmax(guess, dim=2).item()\n",
    "            self.guessed_letter.add(guess)\n",
    "            self.guessed_letter_each.append(chr(guess + 97))\n",
    "\n",
    "            # Store correct response (label) for the model\n",
    "            correct_response = self.encode_correct_response()\n",
    "            correct_response_seen.append(correct_response)\n",
    "\n",
    "            # Update remaining letters and lives left based on the guess\n",
    "            if guess in self.remain_letters:  # Only remove guess when the guess is correct\n",
    "                self.remain_letters.remove(guess)\n",
    "\n",
    "            if correct_response_seen[-1][guess] < 0.0000001:  # Which means we made a wrong guess\n",
    "                self.lives_left -= 1\n",
    "\n",
    "        # Convert lists to PyTorch tensors\n",
    "        obscured_words_seen = list_to_tensor_convertor(obscured_words_seen)\n",
    "        prev_guess_seen = list_to_tensor_convertor(prev_guess_seen)\n",
    "        correct_response_seen = list_to_tensor_convertor(correct_response_seen)\n",
    "\n",
    "        return obscured_words_seen, prev_guess_seen, correct_response_seen\n",
    "\n",
    "\n",
    "# Class defining the Stateful LSTM module\n",
    "class StatefulLSTM(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super(StatefulLSTM, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTMCell(in_size, out_size)\n",
    "        self.out_size = out_size\n",
    "\n",
    "        self.h = None\n",
    "        self.c = None\n",
    "\n",
    "\n",
    "# Class defining the Stateful LSTM module\n",
    "    def reset_state(self):\n",
    "        self.h = None\n",
    "        self.c = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.data.size()[0]\n",
    "        if self.h is None:\n",
    "            state_size = [batch_size, self.out_size]\n",
    "            self.c = Variable(torch.zeros(state_size))\n",
    "            self.h = Variable(torch.zeros(state_size))\n",
    "            if CUDA:\n",
    "                self.c = self.c.cuda()\n",
    "                self.h = self.h.cuda()\n",
    "\n",
    "        self.h, self.c = self.lstm(x, (self.h, self.c))\n",
    "\n",
    "        return self.h\n",
    "\n",
    "#class for dropping out some layer\n",
    "class LockedDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LockedDropout,self).__init__()\n",
    "        self.m = None\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.m = None\n",
    "\n",
    "    def forward(self, x, dropout=0.5, train=True):\n",
    "        if train==False:\n",
    "            return x\n",
    "        if(self.m is None):\n",
    "            self.m = x.data.new(x.size()).bernoulli_(1 - dropout)\n",
    "        mask = Variable(self.m, requires_grad=False) / (1 - dropout)\n",
    "\n",
    "        return mask * x\n",
    "\n",
    "# Class for implementing Locked Dropout\n",
    "class RNN_model(nn.Module):\n",
    "    def __init__(self, hidden_units=16, target_dim=26):\n",
    "        super(RNN_model, self).__init__()\n",
    "        self.lstm1 = StatefulLSTM(27, hidden_units)\n",
    "        self.bn_lstm1 = nn.BatchNorm1d(hidden_units)\n",
    "        self.dropout1 = LockedDropout()\n",
    "        self.fc = nn.Linear(hidden_units + 26, target_dim)\n",
    "        \n",
    "    # Function to reset the LSTM cell and dropout states\n",
    "    def reset_state(self):\n",
    "        self.lstm1.reset_state()\n",
    "        self.dropout1.reset_state()\n",
    "\n",
    "    def forward(self, obscure_word, prev_guess, train=True):\n",
    "        if len(obscure_word.size()) < 3:\n",
    "            obscure_word = obscure_word.unsqueeze(0)\n",
    "        if len(prev_guess.size()) < 2:\n",
    "            prev_guess = prev_guess.unsqueeze(0)\n",
    "\n",
    "        no_of_timesteps = obscure_word.shape[0]\n",
    "        batch_size = obscure_word.shape[1]\n",
    "        self.reset_state()\n",
    "\n",
    "        outputs = []\n",
    "        for i in range(no_of_timesteps):\n",
    "            h = self.lstm1(obscure_word[i, :, :])\n",
    "            h = self.bn_lstm1(h)\n",
    "            h = self.dropout1(h, dropout=0.1, train=train)\n",
    "\n",
    "            pool = nn.MaxPool1d(batch_size)\n",
    "            h = h.permute(1, 0)  # (batch_size,features,time_steps)\n",
    "            h = h.unsqueeze(0)\n",
    "            out = pool(h)\n",
    "            out = out.squeeze(2)\n",
    "            curr_prev_guess = prev_guess[i, :]\n",
    "            curr_prev_guess = curr_prev_guess.unsqueeze(0)\n",
    "            out = torch.cat((out, curr_prev_guess), 1)\n",
    "            out = self.fc(out)\n",
    "            outputs.append(out)\n",
    "        outputs = torch.stack(outputs)\n",
    "        return outputs\n",
    "\n",
    "# Create an instance of the RNN_model\n",
    "model = RNN_model()\n",
    "print(\"------------------------------------------------------------MODEL DETAILS-------------------------------------------------\\n\")\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code used for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Check if CUDA is available for GPU acceleration\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "# Function to display the game status - original word, guesses, and obscured words seen\n",
    "def show_game(original_word, guesses, obscured_words_seen):\n",
    "    print('Hidden word was \"{}\"'.format(original_word))\n",
    "    for i in range(len(guesses)):\n",
    "        word_seen = ''.join([chr(i + 97) if i != 26 else ' ' for i in obscured_words_seen[i].argmax(axis=1)])\n",
    "        print('Guessed {} after seeing \"{}\"'.format(guesses[i], word_seen))\n",
    "\n",
    "# Function to display the game status - original word, guesses, and obscured words seen\n",
    "def storing_words(file_location):\n",
    "    with open(file_location, \"r\") as text_file:\n",
    "        all_words = text_file.read().splitlines()\n",
    "    return all_words\n",
    "\n",
    "# Function to train the model\n",
    "def train_model():\n",
    "    # get data\n",
    "    root_path = os.getcwd()\n",
    "    file_name = \"words_250000_train.txt\"\n",
    "    file_path = os.path.join(root_path, file_name)\n",
    "    words = storing_words(file_path)\n",
    "    num_words = len(words)\n",
    "\n",
    "    # define model\n",
    "    model = RNN_model(target_dim=26, hidden_units=16)\n",
    "\n",
    "    # define hyper parameter\n",
    "    n_epoch = 6\n",
    "    lr = 0.001\n",
    "    record_step = 100  # output result every 100 words\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    loss_func = nn.BCEWithLogitsLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 15, gamma=0.1)\n",
    "\n",
    "    # start training\n",
    "    start_time = time.perf_counter()\n",
    "    tot_sample = 0\n",
    "    for n in range(n_epoch):\n",
    "        i = 0\n",
    "\n",
    "        while tot_sample < (n + 1) * num_words:\n",
    "            word = words[i]\n",
    "            if len(word) == 1:\n",
    "                continue\n",
    "            i += 1\n",
    "            # generate data in a batch\n",
    "            new_batch = Word2Batch(word=word, model=model)\n",
    "            obscured_word, prev_guess, correct_response = new_batch.game_mimic()\n",
    "            if CUDA:\n",
    "                obscured_word = obscured_word.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            predict = model(obscured_word, prev_guess)\n",
    "            loss = loss_func(predict, correct_response)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # show loss\n",
    "            curr_time = time.perf_counter()\n",
    "            print(\"for word {}, the BCE loss is {:4f}, time used:{:4f}\".format(word, loss.item(), curr_time - start_time))\n",
    "            # show guess status\n",
    "            if i % record_step == 0:\n",
    "                guesses = [chr(i+97) for i in torch.argmax(prev_guess, 1)]\n",
    "                show_game(word, guesses, obscured_word)\n",
    "            tot_sample += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading My Trained Model and some helping functions for guessing the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Function to parse command-line arguments for Hangman game configuration\n",
    "def arg_parser():\n",
    "    parser = argparse.ArgumentParser(description=\"hangman game config\")\n",
    "    parser.add_argument(\"--train_set\", type=str, default=\"words_250000_train.txt\",\n",
    "                        help=\"path of the train dictionary\")\n",
    "    parser.add_argument(\"--lives\", type=int, default=6,\n",
    "                        help=\"upper limit of fail guesses\")\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "# Function to load the pre-trained model\n",
    "def load_model(model_path):\n",
    "    model = RNN_model(target_dim=26, hidden_units=16)\n",
    "    checkpoint = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class HangmanAPI(object):\n",
    "    def __init__(self, access_token=None, session=None, timeout=None,model_path='model.pth',n_gram=2):\n",
    "        # Initialize HangmanAPI object with necessary attributes\n",
    "        self.hangman_url = self.determine_hangman_url()\n",
    "        self.access_token = access_token\n",
    "        self.session = session or requests.Session()\n",
    "        self.timeout = timeout\n",
    "        self.guessed_letters = []\n",
    "        full_dictionary_location=\"words_250000_train.txt\"\n",
    "        self.full_dictionary = self.build_dictionary(full_dictionary_location)\n",
    "        self.full_dictionary_common_letter_sorted = collections.Counter(\"\".join(self.full_dictionary)).most_common()\n",
    "        self.frequency_by_length = self.init_df(self.full_dictionary)\n",
    "        self.n_gram = self.init_n_gram(n_gram)\n",
    "        self.current_dictionary = []\n",
    "        self.history_condition = []\n",
    "        self.model = load_model(model_path)\n",
    "        dictionary_file_location=\"words_250000_train.txt\"\n",
    "        text_file = open(dictionary_file_location,\"r\")\n",
    "\n",
    "        words = text_file.read().splitlines()\n",
    "        self.ngrams=[getNGrams(words,i) for i in range(1,6)]\n",
    "        \n",
    "    @staticmethod\n",
    "    def determine_hangman_url():\n",
    "        # Static method to determine the appropriate hangman URL for the game\n",
    "        links = ['https://trexsim.com', 'https://sg.trexsim.com']\n",
    "\n",
    "        data = {link: 0 for link in links}\n",
    "\n",
    "        for link in links:\n",
    "\n",
    "            requests.get(link)\n",
    "\n",
    "            for i in range(10):\n",
    "                s = time.time()\n",
    "                requests.get(link)\n",
    "                data[link] = time.time() - s\n",
    "\n",
    "        link = sorted(data.items(), key=lambda x: x[1])[0][0]\n",
    "        link += '/trexsim/hangman'\n",
    "        return link\n",
    "        # self.current_dictionary = []\n",
    "        \n",
    "    def buildDict(self):\n",
    "        # Function to build a dictionary from the word file\n",
    "        dictionary_file_location=\"words_250000_train.txt\"\n",
    "        text_file = open(dictionary_file_location,\"r\")\n",
    "        words = text_file.read().splitlines()\n",
    "        text_file.close()\n",
    "        \n",
    "        self.ngrams=[getNGrams(words,i) for i in range(1,6)]\n",
    "        \n",
    "    def ngramprob(self,word,letter ):\n",
    "        # Function to calculate the probability of a letter in the given word based on n-grams\n",
    "        denominator=0\n",
    "        underscroll_location=word.find(\"_\")\n",
    "\n",
    "        for l in string.ascii_lowercase:\n",
    "            \n",
    "            try:\n",
    "                denominator+=self.ngrams[len(word)-1][word[:underscroll_location]+l+word[underscroll_location+1:]]\n",
    "            except:\n",
    "                pass\n",
    "        return self.ngrams[len(word)-1][word[:underscroll_location]+letter+word[underscroll_location+1:]]/denominator\n",
    "\n",
    "\n",
    "            \n",
    "    ##########################################################\n",
    "    # You'll likely not need to modify any of the code below #\n",
    "    ##########################################################\n",
    "    \n",
    "    def build_dictionary(self, dictionary_file_location):\n",
    "        text_file = open(dictionary_file_location,\"r\")\n",
    "        full_dictionary = text_file.read().splitlines()\n",
    "        text_file.close()\n",
    "        return full_dictionary\n",
    "    \n",
    "    def find_by_gram(self, all_gram, pre=None, suff=None):\n",
    "        selected_gram = []\n",
    "        for key, val in all_gram.items():\n",
    "            if (pre is not None) and (key[0] == pre):\n",
    "                selected_gram.append((key[1], val))\n",
    "            if (suff is not None) and (key[1] == suff):\n",
    "                selected_gram.append((key[0], val))\n",
    "\n",
    "        res = {}\n",
    "        for letter, frequency in selected_gram:\n",
    "            if letter not in res:\n",
    "                res[letter] = frequency\n",
    "            else:\n",
    "                res[letter] += frequency\n",
    "        final_res = [(key, val) for key, val in res.items()]\n",
    "        return sorted(final_res, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    def gen_n_gram(self, word, n):\n",
    "        n_gram = []\n",
    "        for i in range(n, len(word)+1):\n",
    "            if word[i-n:i] not in n_gram:\n",
    "                n_gram.append(word[i-n:i])\n",
    "        return n_gram\n",
    "\n",
    "    def init_n_gram(self, n):\n",
    "        n_gram = {-1:[]}\n",
    "        for word in self.full_dictionary:\n",
    "            single_word_gram = self.gen_n_gram(word, n)\n",
    "            if len(word) not in n_gram:\n",
    "                n_gram[len(word)] = single_word_gram\n",
    "            else:\n",
    "                n_gram[len(word)].extend(single_word_gram)\n",
    "            n_gram[-1].extend(single_word_gram)\n",
    "        res = {}\n",
    "        for key in n_gram.keys():\n",
    "            res[key] = collections.Counter(n_gram[key])\n",
    "        return res\n",
    "\n",
    "    def calculate_frequency_from_df(self, df):\n",
    "        key, cnt = np.unique(df.values, return_counts=True)\n",
    "        frequency = [(k, val) for k, val in zip(key, cnt)]\n",
    "        return sorted(frequency, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    def update_df(self, df, condition):\n",
    "        \"\"\"\n",
    "        :param df: dataframe\n",
    "        each column is one location of a word\n",
    "        each row is a word\n",
    "        :param condition: dictionary\n",
    "        key is letter\n",
    "        value is which index does this letter appear\n",
    "        means we only select the words which has letter <value> at index <key>\n",
    "        note that we don't select words that has letter <value> at other index\n",
    "        e.g. if condition = {1:'a'}, then \"app\" is selected while \"aha\" not\n",
    "        :return:\n",
    "        df: updated dataframe\n",
    "        \"\"\"\n",
    "        if len(condition) == 0:\n",
    "            return df\n",
    "\n",
    "        for letter, idx in condition.items():\n",
    "            # find rows satisfy\n",
    "            # 1. corresponding column == val\n",
    "            # 2. all the other column != val\n",
    "            query = \"\"\n",
    "            for i in range(df.shape[1]):\n",
    "                col = df.columns.values[i]\n",
    "                if i in idx:\n",
    "                    query += \"{} == '{}' and \".format(col, letter)\n",
    "                else:\n",
    "                    query += \"{} != '{}' and \".format(col, letter)\n",
    "            query = query[:-5]\n",
    "            new_df = df.query(query)\n",
    "            df = new_df.copy()\n",
    "            del new_df\n",
    "        return df\n",
    "\n",
    "    def init_df(self, dictionary):\n",
    "        \"\"\"\n",
    "        use words list to generate dictionary frequencyuency\n",
    "        each key is word length\n",
    "        each value is a dataframe with column is location of each length\n",
    "        \"\"\"\n",
    "        group_by_length = collections.defaultdict(list)\n",
    "        for word in dictionary:\n",
    "            group_by_length[len(word)].append(word)\n",
    "\n",
    "        res = {}\n",
    "        for key in group_by_length.keys():\n",
    "            word_list = group_by_length[key]\n",
    "            tmp = pd.DataFrame([list(word) for word in word_list])\n",
    "            tmp.columns = [chr(i + 97) for i in range(tmp.shape[1])]\n",
    "            res[key] = tmp\n",
    "        return res\n",
    "\n",
    "    def gen_condition(self, word):\n",
    "        tmp = {i: word[i] for i in range(len(word)) if word[i] != \"_\"}\n",
    "        condition = {}\n",
    "        for key, val in tmp.items():\n",
    "            if val not in condition:\n",
    "                condition[val] = [key]\n",
    "            else:\n",
    "                condition[val].append(key)\n",
    "        return condition\n",
    "\n",
    "    def converting_guessed_word(self, word):\n",
    "        word_idx = [ord(i) - 97 if i != \"_\" else 26 for i in word]\n",
    "        obscured_word = np.zeros((len(word), 27), dtype=np.float32)\n",
    "        for i, j in enumerate(word_idx):\n",
    "            obscured_word[i, j] = 1\n",
    "        return obscured_word\n",
    "    \n",
    "    # function for doing monte_carlo simulation\n",
    "    def monte_carlo_guess(self, word, num_simulations=1000):\n",
    "        # Backup the guessed letters to restore later\n",
    "        guessed_letters_backup = self.guessed_letters.copy()\n",
    "\n",
    "        # Generate a list of remaining letters that have not been guessed\n",
    "        remaining_letters = [chr(ord('a') + i) for i in range(26) if chr(ord('a') + i) not in self.guessed_letters]\n",
    "\n",
    "        # Create a dictionary to store the frequency of each remaining letter in successful simulations\n",
    "        letter_frequencies = {letter: 0 for letter in remaining_letters}\n",
    "\n",
    "        # Perform Monte Carlo simulation to make the best guess based on successful simulations\n",
    "        for _ in range(num_simulations):\n",
    "            # Reset guessed letters to the backup for each simulation\n",
    "            self.guessed_letters = guessed_letters_backup.copy()\n",
    "\n",
    "            # Create a list to represent the current guessed word\n",
    "            guessed_word = list(word.replace('_', random.choice(remaining_letters)))\n",
    "\n",
    "            # Continue guessing until the word is fully guessed or all attempts are used\n",
    "            while '_' in guessed_word:\n",
    "                guess_letter = random.choice(remaining_letters)\n",
    "                self.guessed_letters.append(guess_letter)\n",
    "                for i, char in enumerate(word):\n",
    "                    if char == guess_letter:\n",
    "                        guessed_word[i] = guess_letter\n",
    "\n",
    "            # If the guessed word matches the target word, update the letter frequencies\n",
    "            if ''.join(guessed_word) == word:\n",
    "                for letter in remaining_letters:\n",
    "                    if letter in guessed_word:\n",
    "                        letter_frequencies[letter] += 1\n",
    "\n",
    "        # Restore the guessed letters from the backup\n",
    "        self.guessed_letters = guessed_letters_backup.copy()\n",
    "\n",
    "        # Determine the best guess based on the highest frequency from simulations\n",
    "        best_guess = max(letter_frequencies, key=letter_frequencies.get)\n",
    "\n",
    "        # Return the best guess\n",
    "        return best_guess\n",
    "\n",
    "\n",
    "    def guess(self, word):  \n",
    "        # input word example : \"_ric_t_ \"\n",
    "\n",
    "        # divided word group according to word length\n",
    "        words_grouped = self.frequency_by_length[len(word)]\n",
    "        all_gram = self.n_gram[-1]\n",
    "        # all_gram = self.n_gram[len(word)]\n",
    "\n",
    "        # first guess by letter frequency in each word group\n",
    "        new_condition = self.gen_condition(word)\n",
    "\n",
    "        if len(self.history_condition) != 0 and new_condition != self.history_condition[-1]:\n",
    "            self.history_condition.append(new_condition)\n",
    "\n",
    "        words_grouped = self.update_df(words_grouped, new_condition)\n",
    "        frequency = self.calculate_frequency_from_df(words_grouped)\n",
    "        for i in range(len(frequency)):\n",
    "            if frequency[i][0] not in self.guessed_letters:\n",
    "                return frequency[i][0]\n",
    "\n",
    "        # if we run out of letters, use 2-gram to predict\n",
    "        for i in range(len(word)):\n",
    "            if word[i] == \"_\":  # this is where we should apply 2-gram\n",
    "                if (i == 0) or (word[i-1] == \"_\"):\n",
    "                    guess = self.find_by_gram(all_gram, pre=None, suff=word[i+1])\n",
    "                elif (i == len(word) - 1) or (word[i+1] == \"_\"):\n",
    "                    guess = self.find_by_gram(all_gram, pre=word[i-1], suff=None)\n",
    "                else:\n",
    "                    guess = self.find_by_gram(all_gram, pre=word[i-1], suff=word[i+1])\n",
    "                break\n",
    "\n",
    "        for i in range(len(guess)):\n",
    "            if guess[i][0] not in self.guessed_letters:\n",
    "                return guess[i][0]\n",
    "\n",
    "        # if we run out of 2-gram, use LSTM model to predict\n",
    "        # using LSTM model \n",
    "        # the benefit of LSTM model is to add more uncertainty to the prediction\n",
    "        guessed_multi_hot = np.zeros(26, dtype=np.float32)\n",
    "        # Calculate the vowel count ratio\n",
    "        vowel_ratio = vowel_count(word)\n",
    "        vowel_threshold = 0.6\n",
    " \n",
    "        # Check if the vowel count guessed correctly is more than the threshold.\n",
    "        if vowel_ratio > vowel_threshold:\n",
    "            # Step 3: Remove vowels from guessed_letters.\n",
    "            self.guessed_letters = [letter for letter in self.guessed_letters if letter.lower() not in \"aeiou\"]\n",
    "\n",
    "        for letter in self.guessed_letters:\n",
    "            idx = ord(letter) - 97\n",
    "            guessed_multi_hot[idx] = 1.0\n",
    "\n",
    "        unclear_word = self.converting_guessed_word(word)\n",
    "        unclear_word = np.asarray(unclear_word)\n",
    "        guessed_multi_hot = np.asarray(guessed_multi_hot)\n",
    "        unclear_word = torch.from_numpy(unclear_word)\n",
    "        guessed_multi_hot = torch.from_numpy(guessed_multi_hot)\n",
    "\n",
    "        # Using Monte Carlo simulation to make the prediction of LSTM more stable\n",
    "        # predictions = []\n",
    "        # for _ in range(10):  # We can adjust the number of Monte Carlo simulations as per our needs\n",
    "        #     out = self.model(unclear_word, guessed_multi_hot)\n",
    "        #     guess = torch.argmax(out, dim=2).item()\n",
    "        #     predictions.append(guess)\n",
    "\n",
    "        # best_guess = chr(max(set(predictions), key=predictions.count) + 97)\n",
    "        # return best_guess\n",
    "        out = self.model(unclear_word, guessed_multi_hot)\n",
    "        guess = torch.argmax(out, dim=2).item()\n",
    "        guess = chr(guess + 97)\n",
    "        return guess\n",
    "\n",
    "\n",
    "    def build_dictionary(self, dictionary_file_location):\n",
    "        text_file = open(dictionary_file_location, \"r\")\n",
    "        full_dictionary = text_file.read().splitlines()\n",
    "        text_file.close()\n",
    "        return full_dictionary\n",
    "\n",
    "    def get_current_word(self):\n",
    "        \"\"\"\n",
    "        combine target word and guessed letters to generate obscured word\n",
    "        \"\"\"\n",
    "        word_seen = [letter if letter in self.guessed_letters else \"_\" for letter in self.target_word]\n",
    "        return word_seen              \n",
    "    \n",
    "    def start_game(self, practice=True, verbose=True):\n",
    "        # reset guessed letters to empty set and current plausible dictionary to the full dictionary\n",
    "        self.guessed_letters = []\n",
    "        # self.current_dictionary = self.full_dictionary\n",
    "                         \n",
    "        response = self.request(\"/new_game\", {\"practice\":practice})\n",
    "        if response.get('status')==\"approved\":\n",
    "            game_id = response.get('game_id')\n",
    "            word = response.get('word')\n",
    "            word=word.split(\" \")[:-1]\n",
    "            print(\"Word:\",word)\n",
    "            tries_remains = response.get('tries_remains')\n",
    "            if verbose:\n",
    "                print(\"Successfully start a new game! Game ID: {0}. # of tries remaining: {1}. Word: {2}.\".format(game_id, tries_remains, word))\n",
    "            while tries_remains>0:\n",
    "                # get guessed letter from user code\n",
    "                guess_letter = self.guess(word)\n",
    "                    \n",
    "                # append guessed letter to guessed letters field in hangman object\n",
    "                self.guessed_letters.append(guess_letter)\n",
    "                if verbose:\n",
    "                    print(\"Guessing letter: {0}\".format(guess_letter))\n",
    "                    \n",
    "                try:    \n",
    "                    res = self.request(\"/guess_letter\", {\"request\":\"guess_letter\", \"game_id\":game_id, \"letter\":guess_letter})\n",
    "                except HangmanAPIError:\n",
    "                    print('HangmanAPIError exception caught on request.')\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print('Other exception caught on request.')\n",
    "                    raise e\n",
    "               \n",
    "                if verbose:\n",
    "                    print(\"Sever response: {0}\".format(res))\n",
    "                status = res.get('status')\n",
    "                tries_remains = res.get('tries_remains')\n",
    "                if status==\"success\":\n",
    "                    if verbose:\n",
    "                        print(\"Successfully finished game: {0}\".format(game_id))\n",
    "                    return True\n",
    "                elif status==\"failed\":\n",
    "                    reason = res.get('reason', '# of tries exceeded!')\n",
    "                    if verbose:\n",
    "                        print(\"Failed game: {0}. Because of: {1}\".format(game_id, reason))\n",
    "                    return False\n",
    "                elif status==\"ongoing\":\n",
    "                    word = res.get('word')\n",
    "                    word=word.split(\" \")[:-1]\n",
    "                    \n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"Failed to start a new game\")\n",
    "        return status==\"success\"\n",
    "        \n",
    "    def my_status(self):\n",
    "        return self.request(\"/my_status\", {})\n",
    "    \n",
    "    def offline(self,wordtobeguessed):\n",
    "        self.guessed_letters=[]\n",
    "        tries_remains=6\n",
    "        word = \"_ \" * len(wordtobeguessed)\n",
    "        assert len(word) == len(wordtobeguessed) *2\n",
    "        while tries_remains>0:\n",
    "                # get guessed letter from user code\n",
    "            guess_letter = self.guess(word)\n",
    "            flag=False\n",
    "            for index in range(len(wordtobeguessed)):\n",
    "                if wordtobeguessed[index]==guess_letter:\n",
    "                    word=word[:2*index]+guess_letter+word[2*index+1:]\n",
    "                    flag=True\n",
    "            if flag==False:\n",
    "                tries_remains-=1\n",
    "                print(\"Wrong guess, you have\",tries_remains,\"tries left\")\n",
    "            if \"_\" not in word:\n",
    "                print(\"You won!\")\n",
    "                break\n",
    "            # append guessed letter to guessed letters field in hangman object\n",
    "            self.guessed_letters.append(guess_letter)\n",
    "            # time.sleep(0.5)\n",
    "            print(\"Guessed letter: {0}\".format(guess_letter))\n",
    "            print(\"Current word: {0}\".format(word))\n",
    "            \n",
    "            # tries_remains -=1\n",
    "    def request(\n",
    "            self, path, args=None, post_args=None, method=None):\n",
    "        if args is None:\n",
    "            args = dict()\n",
    "        if post_args is not None:\n",
    "            method = \"POST\"\n",
    "\n",
    "        # Add `access_token` to post_args or args if it has not already been\n",
    "        # included.\n",
    "        if self.access_token:\n",
    "            # If post_args exists, we assume that args either does not exists\n",
    "            # or it does not need `access_token`.\n",
    "            if post_args and \"access_token\" not in post_args:\n",
    "                post_args[\"access_token\"] = self.access_token\n",
    "            elif \"access_token\" not in args:\n",
    "                args[\"access_token\"] = self.access_token\n",
    "\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        num_retry, time_sleep = 50, 2\n",
    "        for it in range(num_retry):\n",
    "            try:\n",
    "                response = self.session.request(\n",
    "                    method or \"GET\",\n",
    "                    self.hangman_url + path,\n",
    "                    timeout=self.timeout,\n",
    "                    params=args,\n",
    "                    data=post_args,\n",
    "                    verify=False\n",
    "                )\n",
    "                break\n",
    "            except requests.HTTPError as e:\n",
    "                response = json.loads(e.read())\n",
    "                raise HangmanAPIError(response)\n",
    "            except requests.exceptions.SSLError as e:\n",
    "                if it + 1 == num_retry:\n",
    "                    raise\n",
    "                time.sleep(time_sleep)\n",
    "\n",
    "        headers = response.headers\n",
    "        if 'json' in headers['content-type']:\n",
    "            result = response.json()\n",
    "        elif \"access_token\" in parse_qs(response.text):\n",
    "            query_str = parse_qs(response.text)\n",
    "            if \"access_token\" in query_str:\n",
    "                result = {\"access_token\": query_str[\"access_token\"][0]}\n",
    "                if \"expires\" in query_str:\n",
    "                    result[\"expires\"] = query_str[\"expires\"][0]\n",
    "            else:\n",
    "                raise HangmanAPIError(response.json())\n",
    "        else:\n",
    "            raise HangmanAPIError('Maintype was not text, or querystring')\n",
    "\n",
    "        if result and isinstance(result, dict) and result.get(\"error\"):\n",
    "            raise HangmanAPIError(result)\n",
    "        return result\n",
    "\n",
    "class HangmanAPIError(Exception):\n",
    "    def __init__(self, result):\n",
    "        self.result = result\n",
    "        self.code = None\n",
    "        try:\n",
    "            self.type = result[\"error_code\"]\n",
    "        except (KeyError, TypeError):\n",
    "            self.type = \"\"\n",
    "\n",
    "        try:\n",
    "            self.message = result[\"error_description\"]\n",
    "        except (KeyError, TypeError):\n",
    "            try:\n",
    "                self.message = result[\"error\"][\"message\"]\n",
    "                self.code = result[\"error\"].get(\"code\")\n",
    "                if not self.type:\n",
    "                    self.type = result[\"error\"].get(\"type\", \"\")\n",
    "            except (KeyError, TypeError):\n",
    "                try:\n",
    "                    self.message = result[\"error_msg\"]\n",
    "                except (KeyError, TypeError):\n",
    "                    self.message = result\n",
    "\n",
    "        Exception.__init__(self, self.message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Usage Examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To start a new game:\n",
    "1. Make sure you have implemented your own \"guess\" method.\n",
    "2. Use the access_token that we sent you to create your HangmanAPI object. \n",
    "3. Start a game by calling \"start_game\" method.\n",
    "4. If you wish to test your function without being recorded, set \"practice\" parameter to 1.\n",
    "5. Note: You have a rate limit of 20 new games per minute. DO NOT start more than 20 new games within one minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "api = HangmanAPI(access_token=\"60db3abb051e79a377b71a6b8fc2eb\", timeout=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "HangmanAPIError",
     "evalue": "{'error': 'Your account has been deactivated!'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHangmanAPIError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m api\u001b[39m.\u001b[39;49mstart_game(practice\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[33], line 324\u001b[0m, in \u001b[0;36mHangmanAPI.start_game\u001b[1;34m(self, practice, verbose)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mguessed_letters \u001b[39m=\u001b[39m []\n\u001b[0;32m    322\u001b[0m \u001b[39m# self.current_dictionary = self.full_dictionary\u001b[39;00m\n\u001b[1;32m--> 324\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39m/new_game\u001b[39;49m\u001b[39m\"\u001b[39;49m, {\u001b[39m\"\u001b[39;49m\u001b[39mpractice\u001b[39;49m\u001b[39m\"\u001b[39;49m:practice})\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapproved\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    326\u001b[0m     game_id \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mgame_id\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[33], line 456\u001b[0m, in \u001b[0;36mHangmanAPI.request\u001b[1;34m(self, path, args, post_args, method)\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[39mraise\u001b[39;00m HangmanAPIError(\u001b[39m'\u001b[39m\u001b[39mMaintype was not text, or querystring\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m result\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 456\u001b[0m     \u001b[39mraise\u001b[39;00m HangmanAPIError(result)\n\u001b[0;32m    457\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mHangmanAPIError\u001b[0m: {'error': 'Your account has been deactivated!'}"
     ]
    }
   ],
   "source": [
    "api.start_game(practice=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing practice games:\n",
    "You can use the command below to play up to 100,000 practice games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: ['_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
      "Successfully start a new game! Game ID: 71cc6c98610c. # of tries remaining: 6. Word: ['_', '_', '_', '_', '_', '_', '_', '_', '_'].\n",
      "Guessing letter: e\n",
      "Sever response: {'game_id': '71cc6c98610c', 'status': 'ongoing', 'tries_remains': 5, 'word': '_ _ _ _ _ _ _ _ _ '}\n",
      "Guessing letter: i\n",
      "Sever response: {'game_id': '71cc6c98610c', 'status': 'ongoing', 'tries_remains': 5, 'word': '_ _ _ _ _ _ _ i _ '}\n",
      "Guessing letter: a\n",
      "Sever response: {'game_id': '71cc6c98610c', 'status': 'ongoing', 'tries_remains': 5, 'word': '_ a _ a _ _ _ i _ '}\n",
      "Guessing letter: c\n",
      "Sever response: {'game_id': '71cc6c98610c', 'status': 'ongoing', 'tries_remains': 5, 'word': '_ a c a _ _ _ i _ '}\n",
      "Guessing letter: r\n",
      "Sever response: {'game_id': '71cc6c98610c', 'status': 'ongoing', 'tries_remains': 5, 'word': '_ a c a r _ _ i _ '}\n",
      "Guessing letter: l\n",
      "Sever response: {'game_id': '71cc6c98610c', 'status': 'ongoing', 'tries_remains': 4, 'word': '_ a c a r _ _ i _ '}\n",
      "Guessing letter: t\n",
      "Sever response: {'game_id': '71cc6c98610c', 'status': 'ongoing', 'tries_remains': 3, 'word': '_ a c a r _ _ i _ '}\n",
      "Guessing letter: m\n",
      "Sever response: {'game_id': '71cc6c98610c', 'status': 'ongoing', 'tries_remains': 3, 'word': 'm a c a r _ _ i _ '}\n",
      "Guessing letter: o\n",
      "Sever response: {'game_id': '71cc6c98610c', 'status': 'ongoing', 'tries_remains': 3, 'word': 'm a c a r o _ i _ '}\n",
      "Guessing letter: n\n",
      "Sever response: {'game_id': '71cc6c98610c', 'status': 'ongoing', 'tries_remains': 3, 'word': 'm a c a r o n i _ '}\n",
      "Guessing letter: s\n",
      "Sever response: {'game_id': '71cc6c98610c', 'status': 'success', 'tries_remains': 3, 'word': 'm a c a r o n i s '}\n",
      "Successfully finished game: 71cc6c98610c\n",
      "practice success rate so far =  1.0\n",
      "Word: ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
      "Successfully start a new game! Game ID: 879ead2b91de. # of tries remaining: 6. Word: ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'].\n",
      "Guessing letter: i\n",
      "Sever response: {'game_id': '879ead2b91de', 'status': 'ongoing', 'tries_remains': 6, 'word': '_ _ _ _ _ _ _ _ _ _ _ _ _ i _ _ _ _ _ '}\n",
      "Guessing letter: l\n",
      "Sever response: {'game_id': '879ead2b91de', 'status': 'ongoing', 'tries_remains': 6, 'word': '_ _ _ _ _ _ _ _ _ _ _ _ _ i _ _ l l _ '}\n",
      "Guessing letter: a\n",
      "Sever response: {'game_id': '879ead2b91de', 'status': 'ongoing', 'tries_remains': 6, 'word': '_ _ _ _ _ _ _ _ _ _ a _ _ i _ a l l _ '}\n",
      "Guessing letter: h\n",
      "Sever response: {'game_id': '879ead2b91de', 'status': 'ongoing', 'tries_remains': 6, 'word': '_ h _ _ _ h _ _ _ _ a _ _ i _ a l l _ '}\n",
      "Guessing letter: c\n",
      "Sever response: {'game_id': '879ead2b91de', 'status': 'ongoing', 'tries_remains': 6, 'word': '_ h _ _ _ h _ _ _ _ a _ _ i c a l l _ '}\n",
      "Guessing letter: t\n",
      "Sever response: {'game_id': '879ead2b91de', 'status': 'ongoing', 'tries_remains': 6, 'word': '_ h _ t _ h _ _ _ _ a _ t i c a l l _ '}\n",
      "Guessing letter: p\n",
      "Sever response: {'game_id': '879ead2b91de', 'status': 'ongoing', 'tries_remains': 6, 'word': 'p h _ t _ h _ p _ _ a _ t i c a l l _ '}\n",
      "Guessing letter: e\n",
      "Sever response: {'game_id': '879ead2b91de', 'status': 'ongoing', 'tries_remains': 5, 'word': 'p h _ t _ h _ p _ _ a _ t i c a l l _ '}\n",
      "Guessing letter: s\n",
      "Sever response: {'game_id': '879ead2b91de', 'status': 'ongoing', 'tries_remains': 5, 'word': 'p h _ t _ h _ p _ _ a s t i c a l l _ '}\n",
      "Guessing letter: n\n",
      "Sever response: {'game_id': '879ead2b91de', 'status': 'ongoing', 'tries_remains': 5, 'word': 'p h _ t _ h _ p _ n a s t i c a l l _ '}\n",
      "Guessing letter: o\n",
      "Sever response: {'game_id': '879ead2b91de', 'status': 'ongoing', 'tries_remains': 5, 'word': 'p h o t o h _ p o n a s t i c a l l _ '}\n",
      "Guessing letter: y\n",
      "Sever response: {'game_id': '879ead2b91de', 'status': 'success', 'tries_remains': 5, 'word': 'p h o t o h y p o n a s t i c a l l y '}\n",
      "Successfully finished game: 879ead2b91de\n",
      "practice success rate so far =  1.0\n",
      "Word: ['_', '_', '_', '_', '_', '_', '_']\n",
      "Successfully start a new game! Game ID: 1fd9137c10ae. # of tries remaining: 6. Word: ['_', '_', '_', '_', '_', '_', '_'].\n",
      "Guessing letter: e\n",
      "Sever response: {'game_id': '1fd9137c10ae', 'status': 'ongoing', 'tries_remains': 5, 'word': '_ _ _ _ _ _ _ '}\n",
      "Guessing letter: a\n",
      "Sever response: {'game_id': '1fd9137c10ae', 'status': 'ongoing', 'tries_remains': 4, 'word': '_ _ _ _ _ _ _ '}\n",
      "Guessing letter: i\n",
      "Sever response: {'game_id': '1fd9137c10ae', 'status': 'ongoing', 'tries_remains': 4, 'word': '_ _ _ i _ _ _ '}\n",
      "Guessing letter: s\n",
      "Sever response: {'game_id': '1fd9137c10ae', 'status': 'ongoing', 'tries_remains': 3, 'word': '_ _ _ i _ _ _ '}\n",
      "Guessing letter: r\n",
      "Sever response: {'game_id': '1fd9137c10ae', 'status': 'ongoing', 'tries_remains': 2, 'word': '_ _ _ i _ _ _ '}\n",
      "Guessing letter: n\n",
      "Sever response: {'game_id': '1fd9137c10ae', 'status': 'ongoing', 'tries_remains': 1, 'word': '_ _ _ i _ _ _ '}\n",
      "Guessing letter: l\n",
      "Sever response: {'game_id': '1fd9137c10ae', 'status': 'failed', 'tries_remains': 0, 'word': '_ _ _ i _ _ _ '}\n",
      "Failed game: 1fd9137c10ae. Because of: # of tries exceeded!\n",
      "practice success rate so far =  0.6666666666666666\n",
      "Word: ['_', '_', '_', '_', '_', '_', '_']\n",
      "Successfully start a new game! Game ID: f5d1433d7c85. # of tries remaining: 6. Word: ['_', '_', '_', '_', '_', '_', '_'].\n",
      "Guessing letter: e\n",
      "Sever response: {'game_id': 'f5d1433d7c85', 'status': 'ongoing', 'tries_remains': 5, 'word': '_ _ _ _ _ _ _ '}\n",
      "Guessing letter: a\n",
      "Sever response: {'game_id': 'f5d1433d7c85', 'status': 'ongoing', 'tries_remains': 5, 'word': 'a _ _ a _ _ _ '}\n",
      "Guessing letter: s\n",
      "Sever response: {'game_id': 'f5d1433d7c85', 'status': 'ongoing', 'tries_remains': 5, 'word': 'a s _ a _ _ _ '}\n",
      "Guessing letter: r\n",
      "Sever response: {'game_id': 'f5d1433d7c85', 'status': 'ongoing', 'tries_remains': 4, 'word': 'a s _ a _ _ _ '}\n",
      "Guessing letter: t\n",
      "Sever response: {'game_id': 'f5d1433d7c85', 'status': 'ongoing', 'tries_remains': 4, 'word': 'a s _ a t _ _ '}\n",
      "Guessing letter: i\n",
      "Sever response: {'game_id': 'f5d1433d7c85', 'status': 'ongoing', 'tries_remains': 4, 'word': 'a s i a t i _ '}\n",
      "Guessing letter: n\n",
      "Sever response: {'game_id': 'f5d1433d7c85', 'status': 'ongoing', 'tries_remains': 3, 'word': 'a s i a t i _ '}\n",
      "Guessing letter: c\n",
      "Sever response: {'game_id': 'f5d1433d7c85', 'status': 'success', 'tries_remains': 3, 'word': 'a s i a t i c '}\n",
      "Successfully finished game: f5d1433d7c85\n",
      "practice success rate so far =  0.75\n",
      "Word: ['_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
      "Successfully start a new game! Game ID: 54f0218058e3. # of tries remaining: 6. Word: ['_', '_', '_', '_', '_', '_', '_', '_', '_'].\n",
      "Guessing letter: e\n",
      "Sever response: {'game_id': '54f0218058e3', 'status': 'ongoing', 'tries_remains': 6, 'word': '_ _ _ _ _ _ e _ _ '}\n",
      "Guessing letter: s\n",
      "Sever response: {'game_id': '54f0218058e3', 'status': 'ongoing', 'tries_remains': 6, 'word': '_ _ _ _ _ _ e s s '}\n",
      "Guessing letter: n\n",
      "Sever response: {'game_id': '54f0218058e3', 'status': 'ongoing', 'tries_remains': 6, 'word': '_ _ _ _ _ n e s s '}\n",
      "Guessing letter: i\n",
      "Sever response: {'game_id': '54f0218058e3', 'status': 'ongoing', 'tries_remains': 6, 'word': '_ _ _ _ i n e s s '}\n",
      "Guessing letter: o\n",
      "Sever response: {'game_id': '54f0218058e3', 'status': 'ongoing', 'tries_remains': 5, 'word': '_ _ _ _ i n e s s '}\n",
      "Guessing letter: u\n",
      "Sever response: {'game_id': '54f0218058e3', 'status': 'ongoing', 'tries_remains': 4, 'word': '_ _ _ _ i n e s s '}\n",
      "Guessing letter: d\n",
      "Sever response: {'game_id': '54f0218058e3', 'status': 'ongoing', 'tries_remains': 3, 'word': '_ _ _ _ i n e s s '}\n",
      "Guessing letter: l\n",
      "Sever response: {'game_id': '54f0218058e3', 'status': 'ongoing', 'tries_remains': 2, 'word': '_ _ _ _ i n e s s '}\n",
      "Guessing letter: m\n",
      "Sever response: {'game_id': '54f0218058e3', 'status': 'ongoing', 'tries_remains': 1, 'word': '_ _ _ _ i n e s s '}\n",
      "Guessing letter: a\n",
      "Sever response: {'game_id': '54f0218058e3', 'status': 'ongoing', 'tries_remains': 1, 'word': '_ a _ _ i n e s s '}\n",
      "Guessing letter: t\n",
      "Sever response: {'game_id': '54f0218058e3', 'status': 'ongoing', 'tries_remains': 1, 'word': '_ a t t i n e s s '}\n",
      "Guessing letter: b\n",
      "Sever response: {'game_id': '54f0218058e3', 'status': 'failed', 'tries_remains': 0, 'word': '_ a t t i n e s s '}\n",
      "Failed game: 54f0218058e3. Because of: # of tries exceeded!\n",
      "practice success rate so far =  0.6\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "[total_practice_runs_,total_recorded_runs,total_recorded_successes,total_practice_successes_] = api.my_status()\n",
    "for _ in range(100):\n",
    "    api.start_game(practice=1,verbose=True)\n",
    "    [total_practice_runs,total_recorded_runs,total_recorded_successes,total_practice_successes] = api.my_status() # Get my game stats: (# of tries, # of wins)\n",
    "    # practice_success_rate = total_practice_successes / total_practice_runs\n",
    "    print('practice success rate so far = ' , (total_practice_successes-total_practice_successes_)/(total_practice_runs-total_practice_runs_))\n",
    "print(total_practice_successes-total_practice_successes_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing recorded games:\n",
    "Please finalize your code prior to running the cell below. Once this code executes once successfully your submission will be finalized. Our system will not allow you to rerun any additional games.\n",
    "\n",
    "Please note that it is expected that after you successfully run this block of code that subsequent runs will result in the error message \"Your account has been deactivated\".\n",
    "\n",
    "Once you've run this section of the code your submission is complete. Please send us your source code via email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing  0  th game\n"
     ]
    },
    {
     "ename": "HangmanAPIError",
     "evalue": "{'error': 'Your account has been deactivated!'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHangmanAPIError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPlaying \u001b[39m\u001b[39m'\u001b[39m, i, \u001b[39m'\u001b[39m\u001b[39m th game\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39m# Uncomment the following line to execute your final runs. Do not do this until you are satisfied with your submission\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m api\u001b[39m.\u001b[39;49mstart_game(practice\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# DO NOT REMOVE as otherwise the server may lock you out for too high frequency of requests\u001b[39;00m\n\u001b[0;32m      7\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m0.5\u001b[39m)\n",
      "Cell \u001b[1;32mIn[33], line 324\u001b[0m, in \u001b[0;36mHangmanAPI.start_game\u001b[1;34m(self, practice, verbose)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mguessed_letters \u001b[39m=\u001b[39m []\n\u001b[0;32m    322\u001b[0m \u001b[39m# self.current_dictionary = self.full_dictionary\u001b[39;00m\n\u001b[1;32m--> 324\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39m/new_game\u001b[39;49m\u001b[39m\"\u001b[39;49m, {\u001b[39m\"\u001b[39;49m\u001b[39mpractice\u001b[39;49m\u001b[39m\"\u001b[39;49m:practice})\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapproved\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    326\u001b[0m     game_id \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mgame_id\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[33], line 456\u001b[0m, in \u001b[0;36mHangmanAPI.request\u001b[1;34m(self, path, args, post_args, method)\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[39mraise\u001b[39;00m HangmanAPIError(\u001b[39m'\u001b[39m\u001b[39mMaintype was not text, or querystring\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m result\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 456\u001b[0m     \u001b[39mraise\u001b[39;00m HangmanAPIError(result)\n\u001b[0;32m    457\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mHangmanAPIError\u001b[0m: {'error': 'Your account has been deactivated!'}"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    print('Playing ', i, ' th game')\n",
    "    # Uncomment the following line to execute your final runs. Do not do this until you are satisfied with your submission\n",
    "    api.start_game(practice=0,verbose=False)\n",
    "    \n",
    "    # DO NOT REMOVE as otherwise the server may lock you out for too high frequency of requests\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To check your game statistics\n",
    "1. Simply use \"my_status\" method.\n",
    "2. Returns your total number of games, and number of wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "[total_practice_runs,total_recorded_runs,total_recorded_successes,total_practice_successes] = api.my_status() # Get my game stats: (# of tries, # of wins)\n",
    "success_rate = total_recorded_successes/total_recorded_runs\n",
    "print('overall success rate = %.3f' % success_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
